{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNl8G3vHkPSX"
      },
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## Curso: **Procesamiento de Lenguaje Natural**\n",
        "\n",
        "### Tecnológico de Monterrey\n",
        "\n",
        "### Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## Actividad Semana 5\n",
        "\n",
        "### **Vectores Embebidos de OpenAI**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U69mHA6i201G"
      },
      "source": [
        "#### **Nombres y matrículas de los integrantes del equipo:**\n",
        "\n",
        "\n",
        "*   Carolina Gómez Fernández - A01305369\n",
        "*   Javier Alejandro Pérez Garza - A01284386\n",
        "*   Jorge Andrés Santos Gordon - A01652587\n",
        "*   Vanya Karime Betancourt Reyes - A01795070\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCL2p6MA8NuT",
        "outputId": "306f17a6-458d-46af-fce5-b38c8f2a5b10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Aquí deberás incluir todas las librerías que requieras durante esta actividad:\n",
        "\n",
        "import os\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "import spacy\n",
        "\n",
        "from nltk.corpus import stopwords, words\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk import pos_tag\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wc107K-oIV4"
      },
      "outputs": [],
      "source": [
        "# Incluye las celdas necesarias para tu acceso a la API de OpenAI.\n",
        "#!pip install openai\n",
        "import openai\n",
        "import pickle\n",
        "import time\n",
        "openai.api_key = #'key'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c34ZOnna3Gu"
      },
      "source": [
        "# **Pregunta - 1:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeNllxRdmeWg"
      },
      "source": [
        "Descarga los 3 archivos de Canvas y genera un nuevo DataFrame de Pandas con ellos.\n",
        "\n",
        "**Llama simplemente \"df\" a dicho DataFrame.**\n",
        "\n",
        "Los archivos los encuentras en Canvas: amazon5.txt, imdb5.txt, yelp5.txt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_lyEFRkxzC6",
        "outputId": "01fdf8d1-cc12-4db0-ff43-e328c4c87640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "DIR = '/content/drive/MyDrive/Colab Notebooks/MNA/TC5043 - Procesamiento de lenguaje natural/Semana 5'\n",
        "\n",
        "os.chdir(DIR)\n",
        "\n",
        "\n",
        "dfa = pd.read_csv('amazon5.txt', sep='\\t', names=['review','label'], header=None, encoding='utf-8')\n",
        "dfi = pd.read_csv('imdb5.txt', delimiter='\\s{2,}(?=\\d)', names=['review','label'], header=None, engine ='python', encoding='utf-8')\n",
        "dfy = pd.read_csv('yelp5.txt', sep='\\t', names=['review','label'], header=None, encoding='utf-8')\n",
        "\n",
        "\n",
        "df = pd.concat([dfa, dfi, dfy], ignore_index=True)\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-w1xMLYnm9b",
        "outputId": "30817533-cfa2-4a3b-e213-c24e3edbfed4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3000 entries, 0 to 2999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   review  3000 non-null   object\n",
            " 1   label   3000 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 47.0+ KB\n"
          ]
        }
      ],
      "source": [
        "# Verifiquemos la información del DataFrame:\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NfVUcYe1nubT",
        "outputId": "9116b2bb-22a6-43ba-dac0-7a1cc8607262"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2982,\n        \"samples\": [\n          \"We've tried to like this place but after 10+ times I think we're done with them.\",\n          \"The best example of how dumb the writing is when it's established that you can turn the zombie-students back into humans by removing a necklace containing a piece of the meteorite.\",\n          \"It was that loud.Glad to say that the Plantronics 510 maintains a flawless connection to my cell and with no static during normal use.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-389d432a-d790-4e21-a581-aed6531744de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-389d432a-d790-4e21-a581-aed6531744de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-389d432a-d790-4e21-a581-aed6531744de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-389d432a-d790-4e21-a581-aed6531744de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-25dfc622-4154-4bcb-a287-b8b9f1f1d0b4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25dfc622-4154-4bcb-a287-b8b9f1f1d0b4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-25dfc622-4154-4bcb-a287-b8b9f1f1d0b4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              review  label\n",
              "0  So there is no way for me to plug it in here i...      0\n",
              "1                        Good case, Excellent value.      1\n",
              "2                             Great for the jawbone.      1\n",
              "3  Tied to charger for conversations lasting more...      0\n",
              "4                                  The mic is great.      1"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Y veamos sus primeros registros:\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfZZ0stLmWJN"
      },
      "source": [
        "# **Pregunta - 2:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F6JF5BommZ6"
      },
      "source": [
        "Realiza el proceso de limpieza. Aplica el preprocesamiento que consideres adecuado.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsnvMp-7oYCM"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "# Consideremos la siguiente lista de palabras asociada a negaciones en inglés:\n",
        "\n",
        "nltk_words = set(words.words())\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "negwords = [ 'no', 'nor', 'not', 'ain', 'aren', \"aren't\", 'don', \"don't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "\n",
        "#Excluimos negwords de stopwords\n",
        "mystopwords =  [x for x in stopwords.words('english') if x not in negwords]\n",
        "\n",
        "X = df.review     # Serie de strings\n",
        "Y = df.label      # Serie de enteros 0s y 1s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt5HxCxygpJC"
      },
      "outputs": [],
      "source": [
        "def clean_tok(doc):\n",
        "  # Eliminamos todo lo que no sean letras\n",
        "  words = re.sub(r'\\b\\w\\b|[^a-zA-Z]',r' ' , doc)\n",
        "\n",
        "  # Elimamos espacios en blanco duplicados\n",
        "  words =  re.sub(r'\\s+', ' ', words)\n",
        "\n",
        "  # Aplicamos tecnica de lemmatizacion\n",
        "  tokens = [wd.lemma_ for wd in nlp(words)]\n",
        "\n",
        "  # Aplicamos stemming en palabras no válidas en inglés\n",
        "  ss = SnowballStemmer(\"english\")\n",
        "  tokens = [token if token in nltk_words else ss.stem(token) for token in tokens]\n",
        "\n",
        "  # Tokenizamos los strings y convertimos los token a minusculas\n",
        "  tokens = [ token.strip().lower() for token in tokens]\n",
        "\n",
        "  # Eliminamos Stopwords\n",
        "  tokens = [token for token in tokens if token not in mystopwords]\n",
        "  #\n",
        "  # Eliminamos caracteres duplicados no validos\n",
        "  tokens = [clean_dup_chars(token) for token in tokens]\n",
        "\n",
        "\n",
        "  return tokens\n",
        "\n",
        "\n",
        "def clean_dup_chars(word):\n",
        "\n",
        " if word not in nltk_words:\n",
        "   if re.search(r'(.)\\1', word):\n",
        "     word = re.sub(r'([a-z])\\1', r'\\1', word[::-1], count=1)[::-1]\n",
        "     return clean_dup_chars(word)\n",
        "   else:\n",
        "    return word\n",
        " else:\n",
        "  return word\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OYv-Whmf8aV"
      },
      "outputs": [],
      "source": [
        "# Aplicamos el proceso de limpieza/normalización adicionales:\n",
        "\n",
        "Xclean = [clean_tok(x) for x in X ]\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jlQuoI2o33T",
        "outputId": "09d35ce3-5dd7-4bea-87a0-10362ac9a6a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['no', 'way', 'plug', 'us', 'unless', 'go', 'converter']\n",
            "['good', 'case', 'excellent', 'value']\n",
            "['great', 'jawbone']\n",
            "['tie', 'charger', 'conversation', 'last', 'minute', 'major', 'problem']\n",
            "['mic', 'great']\n"
          ]
        }
      ],
      "source": [
        "# Despleguemos los primeros comentarios después de tu proceso de limpieza:\n",
        "\n",
        "for x in Xclean[0:5]:\n",
        "  print(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygchEdcKqIzU"
      },
      "source": [
        "# **Pregunta - 3:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wEIOkkl9Dot"
      },
      "source": [
        "\n",
        "Realicemos una partición aleatoria con los mismos porcentajes de la práctica pasada para poder comparar dichos resultados con los de\n",
        "esta actividad, a saber, 70%, 15% y 15%, para entrenamiento, validación y prueba, respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0SAcYdq9X0w",
        "outputId": "2598199a-6af6-4071-bc64-4dd5ada044b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X,y Train: 2100 2100\n",
            "X,y Val: 450 450\n",
            "X,y Test 450 450\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ************* Inicia la sección de agregar código:*****************************\n",
        "\n",
        "x_train, x_val_and_test, y_train, y_val_and_test = train_test_split(Xclean, Y, train_size=.70, shuffle=True, random_state=1)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_val_and_test, y_val_and_test, test_size=.50, shuffle=True, random_state=17)\n",
        "\n",
        "\n",
        "# *********** Termina la sección de agregar código *************\n",
        "\n",
        "\n",
        "# verificemos las dimensiones obtenidas:\n",
        "print('X,y Train:', len(x_train), len(y_train))\n",
        "print('X,y Val:', len(x_val), len(y_val))\n",
        "print('X,y Test', len(x_test), len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qjKoEqiqBN1"
      },
      "source": [
        "# **Pregunta - 4:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jENsKiN99r3F"
      },
      "source": [
        "\n",
        "\n",
        "Construye tu vocabulario a continuación\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzJntmLPqPqC"
      },
      "outputs": [],
      "source": [
        "# a.\tUsa el conjunto de entrenamiento para generar tu vocabulario\n",
        "#     con un tamaño que consideres adecuado:\n",
        "\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "midiccionario = Counter()\n",
        "\n",
        "for k in range(len(x_train)):\n",
        "  midiccionario.update(x_train[k])\n",
        "\n",
        "min_freq = 3\n",
        "min_word_len = 3\n",
        "\n",
        "midiccionario = {token: freq for token, freq in midiccionario.items()\n",
        "                 if freq >= min_freq and len(token) >= min_word_len}\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTDZ0Rr86CUP",
        "outputId": "e82f10c0-37b1-4c13-df8d-4bdcda770944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Longitud del vocabulario generado:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "907"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# b.\tIndica el tamaño del vocabulario generado.\n",
        "\n",
        "print('Longitud del vocabulario generado:')\n",
        "\n",
        "\n",
        "# ******* Inicia la sección de agregar código: ***********\n",
        "\n",
        "\n",
        "len(midiccionario)\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDa4EhTqrw15"
      },
      "source": [
        "c.\t¿Por qué debe usarse solamente el conjunto de entrenamiento para generar el vocabulario?\n",
        "\n",
        "\n",
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "Porque si usamos los otros dos conjuntos, corremos el riesgo de tener filtrado de información (vería los inputs de test/train), lo cual afectaría las métricas de desempeño de los modelos al hacer prueba y validación, y dar una idea \"inflada\" de su verdadera precisión.\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ykjxQI3rpxx",
        "outputId": "549016cd-93ab-404c-d5df-fa4d0fabb30f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X,y Train: 2100 2100\n",
            "X,y Val: 450 450\n",
            "X,y Test 450 450\n"
          ]
        }
      ],
      "source": [
        "# d.\tCon el vocabulario generado, filtra los conjuntos de entrenamiento,\n",
        "#     validación y prueba para que todos los comentarios usen solamente las\n",
        "#     palabras de este vocabulario.\n",
        "\n",
        "#     Llamar train_x, val_x y test_x a estos tres conjuntos.\n",
        "\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "\n",
        "train_x = []\n",
        "for ss in x_train:\n",
        "  train_x.append([w for w in ss if w in midiccionario])\n",
        "\n",
        "val_x = []\n",
        "for ss in x_val:\n",
        "  val_x.append([w for w in ss if w in midiccionario])\n",
        "\n",
        "test_x = []\n",
        "for ss in x_test:\n",
        "  test_x.append([w for w in ss if w in midiccionario])\n",
        "\n",
        "\n",
        "print('X,y Train:', len(train_x), len(y_train))\n",
        "print('X,y Val:', len(val_x), len(y_val))\n",
        "print('X,y Test', len(test_x), len(y_test))\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYF2RGuPtQTC",
        "outputId": "948b1909-fb02-4d2c-eca4-1ae31736647c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['star', 'don', 'much', 'well', 'people', 'like', 'waste']\n",
            "['special', 'suck']\n",
            "['pay', 'bill', 'not', 'tip', 'feel', 'server', 'terrible', 'job']\n",
            "['call', 'cook', 'steak', 'don', 'understand']\n",
            "['however', 'keypad', 'tinny', 'sometimes', 'wrong', 'button']\n"
          ]
        }
      ],
      "source": [
        "# Vemos el resultado de los primeros comentarios del conjunto de entrenamiento:\n",
        "\n",
        "for ss in train_x[0:5]:\n",
        "  print(ss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS0Hxj25vTWh"
      },
      "source": [
        "# **Pregunta - 5:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnHHAza5_P5Z"
      },
      "source": [
        "\n",
        "#### **Incluye aquí un resumen de las características y diferencias que tiene al menos los tres modelos de OpenAI indicados: \"text-embedding-3-small\", \"text-embedding-3-large\" y \"text-embedding-ada-002\".**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTI9xSgF_Xc8"
      },
      "source": [
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "Los siguientes tres modelos son opciones que OpenAI ofrece para hacer embeding de texto:\n",
        "1. \"text-embedding-ada-002\": Este embedding tiene 1536 dimensiones, y su costo de procesamiento es bajo en comparación a otras opciones. Su precisión es menor a la de sus contrapartes, pero es útil para casos de uso básicos. Fue de los primeros modelos lanzados por OpenAI, en 2022.\n",
        "2. \"text-embedding-3-small\": Lanzado en 2024, es la evolución del modelo ada-002. Su precisión es mayor, pero mantiene las mismas dimensiones (1536). El costo de procesamiento es similar al de ada-002, y permite ajustar la dimensión de la salida\n",
        "3. \"text-embedding-3-large\": Es un complemento a su versión small, con 3072 dimensiones. Su precisión es la más alta de las 3 opciones, al igual que su costo. Es la mejor opción para tareas complejas, que requieren una comprensión profunda del texto y sus relaciones.\n",
        "\n",
        "**Referencias:**\n",
        "\n",
        "OpenAI. (2025). Vector Embeddings. Recuperado de https://platform.openai.com/docs/guides/embeddings#embedding-models\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToqRl7fT_fn2"
      },
      "source": [
        "# **Pregunta - 6:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKqQk03oqoOD"
      },
      "source": [
        "#### **Diccionario clave-valor de palabras del diccionario y vectores embebidos.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdK-jMfLxHLY",
        "outputId": "e81a5873-0140-4bba-d80f-32019727c49b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de palabras embebidas: 907\n",
            "Tokens de OpenAI utilizados: 1237\n"
          ]
        }
      ],
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "# Generar lista ordenada\n",
        "vocabulario = list(midiccionario.keys())\n",
        "\n",
        "# Diccionario para almacenar los vectores de palabras\n",
        "embedding_dict = {}\n",
        "\n",
        "# Contador de tokens\n",
        "total_tokens = 0\n",
        "batch_size = 100\n",
        "\n",
        "# Modelo a usar\n",
        "embedding_model = \"text-embedding-3-small\"\n",
        "\n",
        "# Llamadas a la API\n",
        "for i in range(0, len(vocabulario), batch_size):\n",
        "        batch = vocabulario[i:i+batch_size]\n",
        "        response = openai.embeddings.create(\n",
        "        input=batch,\n",
        "        model=embedding_model)\n",
        "\n",
        "        tokens_used = response.usage.total_tokens\n",
        "        total_tokens = total_tokens + tokens_used\n",
        "\n",
        "        for j, embedding_data in enumerate(response.data):\n",
        "          palabra = batch[j]\n",
        "          vector = embedding_data.embedding\n",
        "          embedding_dict[palabra] = vector\n",
        "\n",
        "        # Timer\n",
        "        time.sleep(0.5)\n",
        "\n",
        "# Guardar los embeddings y etiquetas\n",
        "with open(\"embedding_dict.pkl\", \"wb\") as f:\n",
        "    pickle.dump(embedding_dict, f)\n",
        "\n",
        "print(\"Total de palabras embebidas:\", len(embedding_dict))\n",
        "print(\"Tokens de OpenAI utilizados:\", total_tokens)\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4S7q0yR0Mpi"
      },
      "source": [
        "# **Pregunta - 7:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyeOrkoaC1eq"
      },
      "source": [
        "\n",
        "\n",
        "Generamos los vectores embebidos a partir de los conjuntos de entrenamiento, validación y prueba.\n",
        "\n",
        "Los llamaremos trainEmb, valEmb y testEmb, respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnfQpkxg0Usq"
      },
      "outputs": [],
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "with open(\"embedding_dict.pkl\", \"rb\") as f:\n",
        "  embedding_dict = pickle.load(f)\n",
        "\n",
        "dim = len(next(iter(embedding_dict.values())))\n",
        "\n",
        "# Convertir train_x en vectores promediados\n",
        "trainEmb = []\n",
        "for review in train_x:\n",
        "  review_vectors = []\n",
        "  for word in review:\n",
        "    if word in embedding_dict:\n",
        "      review_vectors.append(embedding_dict[word])\n",
        "  if len(review_vectors) > 0:\n",
        "    emb = np.mean(review_vectors, axis=0)\n",
        "  else:\n",
        "    emb = np.zeros(dim)\n",
        "  trainEmb.append(emb)\n",
        "\n",
        "# Convertir val_x en vectores promediados\n",
        "valEmb = []\n",
        "for review in val_x:\n",
        "  review_vectors = []\n",
        "  for word in review:\n",
        "    if word in embedding_dict:\n",
        "      review_vectors.append(embedding_dict[word])\n",
        "  if len(review_vectors) > 0:\n",
        "    emb = np.mean(review_vectors, axis=0)\n",
        "  else:\n",
        "    emb = np.zeros(dim)\n",
        "  valEmb.append(emb)\n",
        "\n",
        "# Convertir test_x en vectores promediados\n",
        "testEmb = []\n",
        "for review in test_x:\n",
        "  review_vectors = []\n",
        "  for word in review:\n",
        "    if word in embedding_dict:\n",
        "      review_vectors.append(embedding_dict[word])\n",
        "  if len(review_vectors) > 0:\n",
        "    emb = np.mean(review_vectors, axis=0)\n",
        "  else:\n",
        "    emb = np.zeros(dim)\n",
        "  testEmb.append(emb)\n",
        "\n",
        "# Convertir listas a arreglos de numpy para entrenamiento posterior\n",
        "trainEmb = np.array(trainEmb)\n",
        "valEmb = np.array(valEmb)\n",
        "testEmb = np.array(testEmb)\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3BBF96D0N8Z",
        "outputId": "58448ef1-bf25-47de-e0ba-23ecca1cc2a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train-Emb: (2100, 1536)\n",
            "Val-Emb: (450, 1536)\n",
            "Test-Emb: (450, 1536)\n"
          ]
        }
      ],
      "source": [
        "# Veamos las dimensiones de cada conjunto embebido:\n",
        "\n",
        "print(\"Train-Emb:\", trainEmb.shape)\n",
        "print(\"Val-Emb:\", valEmb.shape)\n",
        "print(\"Test-Emb:\", testEmb.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pibp1LA91CP_"
      },
      "source": [
        "# **Pregunta - 8:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxC9K0VnGOwG"
      },
      "source": [
        "\n",
        "Utiliza los modelos de regresión logística y bosque aleatorio (random forest) y encuentra sus desempeños.\n",
        "\n",
        "Compara los resultados con los de la semana anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycwjD8ztGOL7",
        "outputId": "190eff83-e560-4f9f-b4c6-0c48420a7c6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy:\n",
            "Train: 86.57%\n",
            "Val:   84.00%\n",
            "Test:  80.89%\n",
            "\n",
            "Classification Report (Logistic Regression):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80       216\n",
            "           1       0.81      0.82      0.82       234\n",
            "\n",
            "    accuracy                           0.81       450\n",
            "   macro avg       0.81      0.81      0.81       450\n",
            "weighted avg       0.81      0.81      0.81       450\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# REGRESIÓN LOGÍSTICA:\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "modeloLR = LogisticRegression(C = 25,\n",
        "                              random_state = 1)\n",
        "\n",
        "modeloLR.fit(trainEmb, y_train)\n",
        "\n",
        "\n",
        "print('Logistic Regression Accuracy:')\n",
        "print(f\"Train: {modeloLR.score(trainEmb, y_train):.2%}\")\n",
        "print(f\"Val:   {modeloLR.score(valEmb, y_val):.2%}\")\n",
        "print(f\"Test:  {modeloLR.score(testEmb, y_test):.2%}\")\n",
        "print('\\nClassification Report (Logistic Regression):')\n",
        "print(classification_report(y_test, modeloLR.predict(testEmb)))\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4n70GHW0sl3",
        "outputId": "5a13bd6c-14e2-4624-f269-dab9f3fb1458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy:\n",
            "Train: 85.24%\n",
            "Val:   80.89%\n",
            "Test:  75.78%\n",
            "\n",
            "Classification Report (Random Forest):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.78      0.76       216\n",
            "           1       0.79      0.74      0.76       234\n",
            "\n",
            "    accuracy                           0.76       450\n",
            "   macro avg       0.76      0.76      0.76       450\n",
            "weighted avg       0.76      0.76      0.76       450\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# BOSQUE ALEATORIO (Random Forest):\n",
        "\n",
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "\n",
        "modeloRF = RandomForestClassifier(n_estimators = 200,\n",
        "                                  min_samples_split = 10,\n",
        "                                  min_samples_leaf = 15,\n",
        "                                  max_leaf_nodes = 10,\n",
        "                                  max_features='sqrt',\n",
        "                                  max_depth=5,\n",
        "                                  n_jobs = -1,\n",
        "                                  random_state = 42)\n",
        "\n",
        "modeloRF.fit(trainEmb,y_train)\n",
        "\n",
        "\n",
        "print('Random Forest Accuracy:')\n",
        "print(f\"Train: {modeloRF.score(trainEmb, y_train):.2%}\")\n",
        "print(f\"Val:   {modeloRF.score(valEmb, y_val):.2%}\")\n",
        "print(f\"Test:  {modeloRF.score(testEmb, y_test):.2%}\")\n",
        "print('\\nClassification Report (Random Forest):')\n",
        "print(classification_report(y_test, modeloRF.predict(testEmb)))\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDIiSHvg0_hm"
      },
      "source": [
        "# **Pregunta - 9:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJJtALGZHrGk"
      },
      "source": [
        "\n",
        "\n",
        "Reporte del mejor modelo con el conjunto de Prueba (Test).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETv4VLjP1GYt",
        "outputId": "8e1c1f33-1655-4519-cf60-5438be77349a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test-accuracy con el mejor modelo 80.89%\n",
            "\n",
            "Matriz de confusión con el mejor modelo:\n",
            "[[172  44]\n",
            " [ 42 192]]\n",
            "\n",
            "Matriz de confusión con el mejor modelo en proporciones:\n",
            "[[0.38222222 0.09777778]\n",
            " [0.09333333 0.42666667]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80       216\n",
            "           1       0.81      0.82      0.82       234\n",
            "\n",
            "    accuracy                           0.81       450\n",
            "   macro avg       0.81      0.81      0.81       450\n",
            "weighted avg       0.81      0.81      0.81       450\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ******* Inlcuye a continuación todas las líneas de código y celdas que requieras: ***********\n",
        "\n",
        "mejor_modelo = modeloLR\n",
        "\n",
        "print('Test-accuracy con el mejor modelo %.2f%%' % (100*mejor_modelo.score(testEmb, y_test)))\n",
        "\n",
        "pred = mejor_modelo.predict(testEmb)\n",
        "print('\\nMatriz de confusión con el mejor modelo:')\n",
        "print(confusion_matrix(y_test, pred, labels=[0,1]))\n",
        "\n",
        "print('\\nMatriz de confusión con el mejor modelo en proporciones:')\n",
        "print(confusion_matrix(y_test, pred, labels=[0,1]) / (pred.shape[0] ))\n",
        "\n",
        "report = classification_report(y_test, pred)\n",
        "print(report)\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbhBUBKJp1MB"
      },
      "source": [
        "# **Pregunta - 10:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzeRZ8Fx2AUT"
      },
      "outputs": [],
      "source": [
        "# Incluye todas las líneas de código y celdas que consideres adecuadas para este ejercicio.\n",
        "\n",
        "#a\n",
        "# Generar lista ordenada\n",
        "Xfull_text = list(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zPSi-H7p6ga",
        "outputId": "aeee1d6a-0ed1-4754-e99e-aa1d6ac2abf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens de OpenAI utilizados: 43804\n"
          ]
        }
      ],
      "source": [
        "#Lista para almacenar los vectores de Xfull_text\n",
        "full_embeddings = []\n",
        "\n",
        "# Contador de tokens\n",
        "total_tokens = 0\n",
        "batch_size = 100\n",
        "\n",
        "# Modelo a usar\n",
        "embedding_model = \"text-embedding-3-small\"\n",
        "\n",
        "# Llamadas a la API\n",
        "for i in range(0, len(Xfull_text), batch_size):\n",
        "    batch = Xfull_text[i:i+batch_size]\n",
        "    response = openai.embeddings.create(\n",
        "        input=batch,\n",
        "        model=embedding_model)\n",
        "\n",
        "    total_tokens = total_tokens + response.usage.total_tokens\n",
        "    for embedding_data in response.data:\n",
        "        full_embeddings.append(embedding_data.embedding)\n",
        "\n",
        "    # Timer\n",
        "    time.sleep(0.5)\n",
        "\n",
        "# Guardar los embeddings y etiquetas\n",
        "with open(\"full_embedding_dict.pkl\", \"wb\") as f:\n",
        "    pickle.dump({\"embeddings\": full_embeddings, \"labels\": list(Y)}, f)\n",
        "\n",
        "\n",
        "print(\"Tokens de OpenAI utilizados:\", total_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c62CGGawKdcr"
      },
      "outputs": [],
      "source": [
        "#b\n",
        "with open(\"full_embedding_dict.pkl\", \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "X_all = np.array(data[\"embeddings\"])\n",
        "Y_all = np.array(data[\"labels\"])\n",
        "\n",
        "# Partición\n",
        "x_train, x_val_test, y_train, y_val_test = train_test_split(X_all, Y_all, train_size=0.70, random_state=1)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test, test_size=0.5, random_state=17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JNydt3-KizO",
        "outputId": "a736cf9e-4b23-48ea-986b-31e06adbc777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy:\n",
            "Train: 99.62%\n",
            "Val:   97.56%\n",
            "Test:  97.78%\n",
            "\n",
            "Classification Report (Logistic Regression):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       216\n",
            "           1       0.98      0.97      0.98       234\n",
            "\n",
            "    accuracy                           0.98       450\n",
            "   macro avg       0.98      0.98      0.98       450\n",
            "weighted avg       0.98      0.98      0.98       450\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#c\n",
        "#Logistic Regression\n",
        "modeloLR = LogisticRegression(C=25, random_state=1)\n",
        "modeloLR.fit(x_train, y_train)\n",
        "\n",
        "print('Logistic Regression Accuracy:')\n",
        "print(f\"Train: {modeloLR.score(x_train, y_train):.2%}\")\n",
        "print(f\"Val:   {modeloLR.score(x_val, y_val):.2%}\")\n",
        "print(f\"Test:  {modeloLR.score(x_test, y_test):.2%}\")\n",
        "print('\\nClassification Report (Logistic Regression):')\n",
        "print(classification_report(y_test, modeloLR.predict(x_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YujNBsmJKq8F",
        "outputId": "4fb157e4-63fe-449a-dce6-395e27aa7822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy:\n",
            "Train: 98.19%\n",
            "Val:   95.78%\n",
            "Test:  96.89%\n",
            "\n",
            "Classification Report (Random Forest):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       216\n",
            "           1       0.98      0.96      0.97       234\n",
            "\n",
            "    accuracy                           0.97       450\n",
            "   macro avg       0.97      0.97      0.97       450\n",
            "weighted avg       0.97      0.97      0.97       450\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Random Forest\n",
        "modeloRF = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=15,\n",
        "    max_leaf_nodes=10,\n",
        "    max_features='sqrt',\n",
        "    max_depth=5,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "modeloRF.fit(x_train, y_train)\n",
        "\n",
        "print('Random Forest Accuracy:')\n",
        "print(f\"Train: {modeloRF.score(x_train, y_train):.2%}\")\n",
        "print(f\"Val:   {modeloRF.score(x_val, y_val):.2%}\")\n",
        "print(f\"Test:  {modeloRF.score(x_test, y_test):.2%}\")\n",
        "print('\\nClassification Report (Random Forest):')\n",
        "print(classification_report(y_test, modeloRF.predict(x_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCkh2WfN1MC1"
      },
      "source": [
        "# **Pregunta - 11:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ySFuDQtVuK5"
      },
      "source": [
        "\n",
        "\n",
        "Incluye tus comentarios finales de la actividad.\n",
        "\n",
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "Se trabajaron 3 archivos CVS llamados amazon5txt, yelp5.txt e imdb5.txt de Canvas. Se generó un solo DataFrame de Pandas con ellos. En particular. El archivo imdb no requirió transformarse para obtener sus 1000 registros. Con los datos obtenidos se realizó un proceso de limpieza.\n",
        "\n",
        "El dataset fue dividido en conjuntos de entrenamiento 70%, validación 15% y prueba 15%, siguiendo las prácticas adecuadas en el entrenamiento de modelos supervisados.\n",
        "\n",
        "Con los datos preparados se construyó el vocabulario, en la pregunta 4 se concluyé que lo mejor es utilizar el conjunto de entrenamiento para evitar sesgos por fuga de datos.\n",
        "\n",
        "Después, se analizaron diferentes modelos de vectores embebidos de OpenAI, llegando a la conclusión que el modelo embedding-3-small era el que se iba a utilizar en el resto de las preguntas de este ejercicio.\n",
        "\n",
        "Posteriormente, se entrenaron dos modelos de clasificación: Regresión Logística y Bosque Aleatorio (Random Forest) y se hizo una comparación entre la limpieza de datos hecha por nosotros y la limpieza hecha por el modelo de embedding de OpenAI. Al utilizar el embedding de Open AI se puede observar que ambos modelos obtuvieron resultados de precisión y recall elevados, que rondan al 98%, lo que sugiere que los embeddings generados capturan muy bien la información necesaria para clasificar los textos.\n",
        "\n",
        "Se utilizó el reporte de clasificación (precision, recall, f1-score, support) para evaluar el desempeño de los modelos, mostrando métricas balanceadas para ambas clases (0 y 1), lo que indica un modelo robusto y bien entrenado.\n",
        "\n",
        "Como conclusión general el uso de embeddings generados por modelos de OpenAI permite aprovechar representaciones semánticas ricas del lenguaje sin necesidad de entrenar modelos complejos desde cero, además la actividad permite regorzar las buenas prácticas en ciencia de datos, como la separación de datos, el uso de validación cruzada implícita, y la comparación objetiva entre modelos.\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgKHmQTbWJT1"
      },
      "source": [
        "# **Fin de la Actividad de Vectores Embebidos - OpenAI**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
