{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hVND8xY2OKY"
      },
      "source": [
        "# **Procesamiento de Lenguaje Natural**\n",
        "\n",
        "## Maestría en Inteligencia Artificial Aplicada\n",
        "#### Tecnológico de Monterrey\n",
        "#### Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "### **Adtividad en Equipos Semanas 7 y 8 : LDA y LMM audio-a-texto**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aimHVFOv23lm"
      },
      "source": [
        "* **Nombres y matrículas:**\n",
        "\n",
        "  *   Elemento de lista\n",
        "  *   Elemento de lista\n",
        "  *   Elemento de lista\n",
        "\n",
        "* **Número de Equipo:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jimvsiVgjMg"
      },
      "source": [
        "* ##### **En cada ejercicio pueden importar los paquetes o librerías que requieran.**\n",
        "\n",
        "* ##### **En cada ejercicio pueden incluir las celdas y líneas de código que deseen.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BtP-Sk0DT-M"
      },
      "source": [
        "# **Ejercicio 1:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh78pKeMghfe"
      },
      "source": [
        "* #### **Liga de los audios de las fábulas de Esopo:** https://www.gutenberg.org/ebooks/21144\n",
        "\n",
        "* #### **Descargar los 10 archivos de audio solicitados: 1, 4, 5, 6, 14, 22, 24, 25, 26, 27.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWt7-UQ9UkXI"
      },
      "outputs": [],
      "source": [
        "#!pip uninstall -y scipy numpy\n",
        "#!pip install numpy==1.25.2\n",
        "#!pip install scipy==1.11.3  # Compatible con numpy>=1.25\n",
        "#!pip install gensim==4.3.2\n",
        "#!pip install bitsandbytes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfs5Zxc9j7Uf",
        "outputId": "d68042a1-4862-4349-dce1-c2d2361ad72d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Directorio con los audios\n",
        "DIR = '/content/drive/MyDrive/Colab Notebooks/LDA'\n",
        "\n",
        "import json\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "from gensim import corpora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUup4C8nHKB5",
        "outputId": "5021bf99-ecc5-4a1f-ea0e-f42d10913857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline, AutoProcessor, AutoModelForSpeechSeq2Seq, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import librosa\n",
        "import torch\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "login(userdata.get('miHuggingFace'))\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Usando dispositivo: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uR9ULdUY6nVe"
      },
      "outputs": [],
      "source": [
        "# Audios a trabajar\n",
        "audio_ids = [1, 4, 5, 6, 14, 22, 24, 25, 26, 27]\n",
        "audio_paths = {f'audio{str(i).zfill(2)}': os.path.join(DIR, f'21144-{i}.mp3') for i in audio_ids}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uYgtCvvJSmq"
      },
      "source": [
        "# **Ejercicio 2a:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAQjVP2HkoZY"
      },
      "source": [
        "* #### **Comenten el por qué del modelo seleccionado para extracción del texto de los audios.**\n",
        "\n",
        "* #### **Extraer el contenido de los audios en texto.**\n",
        "\n",
        "* #### **Sugerencia:** pueden extraerlo en un formato de diccionario, clave:valor $→$ {audio01:fabula01, ...}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2XGo3g3H-VO"
      },
      "outputs": [],
      "source": [
        "audios_data = {}\n",
        "for audio_key, audio_path in audio_paths.items():\n",
        "    if os.path.exists(audio_path):\n",
        "        audio, sample_rate = librosa.load(audio_path,\n",
        "                                          sr=16000   # los modelos Wav2Vec2 requieren un muestreo (sample rate) de 16Hz.\n",
        "                                          )\n",
        "        audios_data[audio_key] = (audio, sample_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473,
          "referenced_widgets": [
            "474cb97f52c74e06b81e5d313a6a2226",
            "0e272cc23eb54913aefb0c9fc1445f10",
            "e53c8b5de7274b10878df939f699cbed",
            "6286b063777440578f68a2d67e121510",
            "fd2033983e5c42caa45a3f96fb797f5f",
            "d56c138a007f409cb688e473c74bdf00",
            "620c9aa569f04785822e5fae6d54d74d",
            "5b72b4635c464ad7831aec25d76dee3d",
            "cfbf95d5800444c6b9201e527b710af6",
            "8ff20f691ca048b0bf4fd3c7d06af3a5",
            "d2073c85a18d49689cd9717ca33b673e",
            "4b617a5d0192470794e117dd3c9e31c0",
            "b9328a20226c4ea690b44d910d4fc84e",
            "77dd2f606d2b493c9f2e08c3a6d576fb",
            "12e9caa0f7974888847db20bbf831ec8",
            "86750d1bd48d4eeba8d82dfe7fccbf31",
            "789f89e4631240dd9eea3e212649a693",
            "c1dd0250a7aa46b998b1bfd8ab56717a",
            "643250fa014343b5ad270b542558021c",
            "94dc0df09da54b7a90ba0f17789b7c8f",
            "43f594690faf46ae8182aaf1623c686b",
            "dc30828bbe7a4b2daf312710e9a1b9ca",
            "8cf8acaefce44d25b72e52a91480f497",
            "40a94730c798440cb623474c1559e279",
            "67817ee9937c40c599e0cd5b2cca6799",
            "e6f05c986f664a929fb4a6695bc0ed53",
            "302a9ac2cb4a4ab5aa26526466d93ecf",
            "cfc7d9c5032e47d389cf58d0ec293cb7",
            "e32e412de26646e18173eeadf0d23aef",
            "d555bad68acf487e80db79119d2400d4",
            "547e1661840148348d23da89754803d9",
            "9a9fa9db0850418eb7b8610f270144cb",
            "cbb29b3a6a73452281587e5d3073afe3",
            "496253e01db94c17b99b106f52831c0a",
            "30b0fc444ff0430d9c00e5d6ac161bf4",
            "e2684509accf4cb59357c36ab7b1cbc2",
            "0517c7f2961842018f66f0f7ae273f20",
            "e918b4b99b61491fae20698a59586955",
            "5858425814284158b1f8ab4581e9e269",
            "daee136e97c3489b873359ff1c6a358e",
            "8cd5f9c983b444cf8205ef459d08279a",
            "e69fb1395ccf4c3ba944834ed6c48ff4",
            "3f52cc113e6e4de1b24c06d309047ef5",
            "c956b04c916f4ce490fb4d88e33af2f8",
            "56c1c06fc75b4c0581d585c278b2b753",
            "8eef0580a55341c4a8c032bc2405c560",
            "6569052356144422ac375651b5ce7fec",
            "b009d9cf34c54e08b42d4e94e77fdf55",
            "2c4efd30ef2c4aa881784c356a8d6c4b",
            "a759d64fd736498597ef711f946a817c",
            "566513167ac94c62a5a7cfdbab1146a9",
            "9fe141173adc4a13a4ef95c7974c40c7",
            "585334792dc7420baaa51339309563c9",
            "b653749188a345c08952e5104b89b1d2",
            "988c9fab69e84f6dafd08c61057130ed",
            "b7b646b78262491cbb96320b2444a75c",
            "ad0417a5f0ad433287596ce680acb2ba",
            "3d149dbf684e442fb398e0ee64640789",
            "5a7d2238195e4edeba9720cf2bf2645c",
            "fc2631af12a14b538797cadbf1870a42",
            "ae4f7a0e6cbc4094b3e2285dba473a85",
            "cfb58152bcbf45b286717e5007762cfd",
            "d50a239a09124e969197b6497763d5c5",
            "a1bde8e24ec8425182c34cba20fbf520",
            "b19b3744ea5f437fb7443f157990a0af",
            "92582a349b204f5cb1e9595e238d69ef",
            "08059c7031684808b149e2136569c046",
            "2f34d402b78b497ea2a07a5b8c5fe5e9",
            "217a11ba931d46359673c48156874193",
            "1553bfa3999d40f0b8bec8531d8380e0",
            "1fd5ee8b4cd34dceae89ac4adebaa812",
            "6b4f0d779c984d7aba3fa317c0b9e6c2",
            "718e7c5fa752402bb4b8061fbde7d506",
            "2a20dbfce55b42eab0066a472fc55e7f",
            "7c19783fde544ce2b5edf200cd3e6729",
            "61618cfe400d486e9de4fbdcc6ce453b",
            "53729ebef55944efa80cca512204c6d9",
            "049bce65d4d34abd8731c6cc2f238f97",
            "04344bb5ffc842569cc1c3b4d584843f",
            "60750b6bf0fa4bdc99b5f9ae01910380",
            "377c033ce67c4114adf2ebf72529717a",
            "0d3042a3e431494ba4ca46947a3d02ee",
            "5c8aaa2c63db4ea8ac3587fec7ae7c2b",
            "7189a208ccec4481b5250de453f507dd",
            "097a83a2f0554c5b935b004cbacb48b4",
            "8156637016dc473dadc17193c154647d",
            "6c53034f61014c90b3de606eb2623ec1",
            "4f6db10433d94de3b1f423d98e6718cc",
            "5ae63ca8c069449896560a9462c4da1b",
            "3ded840a0ccb47f6ac4f1b32d07fa38e",
            "3f204728b2714205bdc5acb8ef7c6852",
            "8fe413a6a8294721a601c6b009534b49",
            "feb721ceefe94988978126ca0326b9a7",
            "9de0d45718cd43dfa7d0c786aae5aefc",
            "ae06b9386a0d4b8fb67c7f60446bfb99",
            "3a0060fe1742483193848f9a205a7863",
            "8a27a994d68f4e51955e43bad4e8a6cd",
            "07f7f9649d244989bcabdab0f01ed37e",
            "618b76ad0b1547a5838561897bcd0d86",
            "0a7b76bd73ee4d178c123cb112f4586b",
            "fd453e6386c14993bd0b351acd2513e5",
            "ee439518f2be4f918200fbaad1ec563e",
            "1ae90d5de4234808b85403493083da2c",
            "a123a1ca1e7344e9ac521c99b64db85b",
            "53f2623bd6ea49d7ae9c152f559cb4ee",
            "441401ed281b43e3909f1bb2c2581da2",
            "3cf0cb26d9aa463294b3e98b556b12fb",
            "1ef2263e69074955902250449db5287b",
            "19ac66fe194c4d73a97023d9253de012",
            "75ccc7c270774118a4eb9c02bbcd4479",
            "e63ccd39f4b846d680cac5f7680c4f76",
            "7cd76b0147ec4273b2fefd24d6893441",
            "30aacbbf14134e5d8d91bfa44301dc3e",
            "ae5f905fa7b6490a9cbd82af789bebc3",
            "d08f890b57ba426e8bb0cc794b74564a",
            "e0e6ada2330e482fa611b6fadc09a867",
            "9d5c551c76424ecfb9a070bacc858c53",
            "a10d0ad058b244dfa09092cc33d6b923",
            "5a83886eaa324e0b949caa9dd891976f",
            "b2bb9549cf3f4d2382eaa1154588a3b2",
            "6bafebdaf05a439eaef33e4e394d5af9"
          ]
        },
        "id": "hvVsMsJwKhcy",
        "outputId": "3d8cece9-37c2-4d0d-e3c9-abeffd49f432"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "474cb97f52c74e06b81e5d313a6a2226",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b617a5d0192470794e117dd3c9e31c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cf8acaefce44d25b72e52a91480f497",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "496253e01db94c17b99b106f52831c0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56c1c06fc75b4c0581d585c278b2b753",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7b646b78262491cbb96320b2444a75c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08059c7031684808b149e2136569c046",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "049bce65d4d34abd8731c6cc2f238f97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ae63ca8c069449896560a9462c4da1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a7b76bd73ee4d178c123cb112f4586b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e63ccd39f4b846d680cac5f7680c4f76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/3.90k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_id = \"openai/whisper-large-v3\"    # una versión ligera de v3\n",
        "\n",
        "# Cargamos el modelo:\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "modelo = AutoModelForSpeechSeq2Seq.from_pretrained(model_id).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGpR1wB1NbBi",
        "outputId": "3d8ef0dc-2f18-4b14-84fb-6d5de5cff27b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda\n"
          ]
        }
      ],
      "source": [
        "asr_pipeline = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=modelo,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    torch_dtype=torch.float32,\n",
        "    device=device,\n",
        "    return_timestamps=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3k5sLGhnO1d",
        "outputId": "524a2d19-07cf-4e8c-dfb6-e9e8fd7f046b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "You have passed language=es, but also have set `forced_decoder_ids` to [[1, None], [2, 50360]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of language=es.\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de audios procesados: 10\n"
          ]
        }
      ],
      "source": [
        "# Diccionario para almacenar los textos extraídos\n",
        "fabulas_raw = {}\n",
        "\n",
        "# Extraer texto de cada audio usando el pipeline\n",
        "for audio_key, (audio, sample_rate) in audios_data.items():\n",
        "    # Configurar los parámetros de generación\n",
        "    generate_kwargs = {\"language\": \"es\"}\n",
        "\n",
        "    # Usar el pipeline\n",
        "    result = asr_pipeline(audio, generate_kwargs=generate_kwargs)\n",
        "\n",
        "    # Extraer solo el texto de la transcripción\n",
        "    transcription = result[\"text\"]\n",
        "    fabulas_raw[audio_key] = transcription\n",
        "\n",
        "print(f\"Total de audios procesados: {len([k for k, v in fabulas_raw.items() if v])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K7mALE8Opzf",
        "outputId": "1d4e1165-ed3f-4964-b4b1-5db6f5a4dd93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'audio01': ' Las Fábulas de Esopo. Grabado para LibriVox.org por Paulino. www.paulino.info Fábula número 61. El lobo y el cordero en el templo. Dándose cuenta de que era perseguido por un lobo, un pequeño corderito decidió refugiarse en un templo cercano. Lo llamó lobo y le dijo que si el sacrificador lo encontraba allí adentro, lo inmolaría a su dios. Mejor así, replicó el cordero, prefiero ser víctima para un dios a tener que perecer en tus colmillos. Si sin remedio vamos a ser sacrificados, más nos vale que sea con el mayor honor. Fin de la fábula. Esta es una grabación del dominio público.',\n",
              " 'audio04': ' Las fábulas de Esopo grabado para LibriVox.org por Roberto Antonio Muñoz Fábula número 64 El lobo y la grulla A un lobo que comía un hueso, se le atragantó el hueso en la garganta y corría por todas partes en busca de auxilio. Encontró en su correa una grulla y le pidió que le salvara de aquella situación, y que enseguida le pagaría por ello. Aceptó la grulla e introdujo su cabeza en la boca del lobo, sacando de la garganta el hueso atravesado Pidió entonces la cancelación de la paga convenida Oye Anida, dijo el lobo, ¿no crees que es suficiente paga con haber sacado tu cabeza sana y salva de mi boca? Nunca hagas favores a malvados, traficantes o corruptos, pues mucha paga tendrías si te dejan sano y salvo Fin de fábula Esta grabación es de dominio público',\n",
              " 'audio05': ' Las fábulas de Sopo, grabado para LibriVox.org por Karen Savage. Fábula número 65. El lobo y el caballo. Pasaba un lobo por un sembrado de cebada, pero como no era comida de su gusto, la dejó y siguió su camino. Encontró al rato a un caballo, y le llevó al campo comentándole la gran cantidad de cebada que había hallado, pero que en vez de comérsela a él mejor se la había dejado porque le agradaba más oír el ruido de sus dientes al masticarla pero el caballo le repuso amigo si los lobos comieran cebada no hubieras preferido complacer a tus oídos sino a tu estómago a todo malvado aunque parezca actuar como bueno no debe de creérsele fin de fábula esta grabación es de dominio público Gracias por ver el video.',\n",
              " 'audio06': ' Las fábulas de Esopo, grabado para LibriVox.org por Alejandro González Calderón. Fábula número 66, El lobo y el asno. Un lobo fue elegido rey entre sus congéneres y decretó una ley ordenando que lo que cada uno capturase en la casa, lo pusiera en común y lo repartiese por partes iguales entre todos. de esta manera ya no tendrían los lobos que devorarse unos a otros en épocas de hambre pero en eso le escuchó un asno que estaba por ahí cerca y moviendo sus orejas le dijo magnífica idea ha brotado de tu corazón pero ¿por qué has escondido todo tu botín en tu cueva? llévalo a la comunidad y repártelo también como lo has decretado el lobo descubierto y confundido derogó su ley Si alguna vez llegas a tener poder de legislar, sé el primero en cumplir tus propias leyes Fin de la fábula, esta grabación es de dominio público',\n",
              " 'audio14': ' Las fábulas de Sopo Grabado para LibriVox.org por Elochito Fábula número 74 El lobo y el cabrito encerrado Protegido por la seguridad del corral de una casa, un cabrito vio pasar a un lobo y comenzó a insultarle burlándose ampliamente de él. El lobo serenamente le replicó Infeliz, sé que no eres tú quien me está insultando sino el sitio en que te encuentras Muy a menudo no es el valor sino la ocasión y el lugar quienes proveen el enfrentamiento arrogante ante los poderosos Fin de la fábula Esta grabación es del dominio público Gracias.',\n",
              " 'audio22': ' Las fábulas de Esopo Grabado para LibriVox.org por Elochito Fábula número 82 El perro y la almeja Un perro de esos, acostumbrados a comer huevos, al ver una almeja, no lo pensó dos veces, y creyendo que se trataba de un huevo, se la tragó inmediatamente. Desgarradas luego sus entrañas, se sintió muy mal, y se dijo, bien merecido lo tengo por creer que todo lo que veo redondo son huevos nunca tomes un asunto sin antes reflexionar para no entrar luego en extrañas dificultades Fin de la fábula. Esta grabación es del dominio público.',\n",
              " 'audio24': ' Las fábulas de Sopo. Grabado para LibriVox.org por Karen Savage. Fábula número 84. El perro y el reflejo en el río. Badeaba un perro un río, llevando en su hocico un sabroso pedazo de carne. Vio su propio reflejo en el agua del río, y creyó que aquel reflejo era en realidad otro perro que llevaba un trozo de carne mayor que el suyo. Y deseando adueñarse del pedazo ajeno, soltó el suyo para arrebatar el trozo a su supuesto compadre, pero el resultado fue que se quedó sin el propio y sin el ajeno, este porque no existía, sólo era un reflejo, y el otro, el verdadero, porque se lo llevó a la corriente. Nunca codices el bien ajeno, pues puedes perder lo que ya has adquirido con tu esfuerzo. Fin de fábula Esta grabación es de dominio público',\n",
              " 'audio25': ' Las Fábulas de Esopo Grabado para LibreVox.org Fábula número 85 El perro y el carnicero Penetró un perro en una carnicería y notando que el carnicero estaba muy ocupado con sus clientes, cogió un trozo de carne y salió corriendo. Se volvió el carnicero y viéndole huir y sin poder hacer nada exclamó. Oye amigo, allí donde te encuentre no dejaré de mirarte. No esperes a que suceda un accidente para pensar en cómo evitarlo. Fin de fábula. Esta grabación es de dominio público. Gracias por ver el video.',\n",
              " 'audio26': ' Las fábulas de Esopo Grabado para LibriVox.org por Elochito Fábula número 86 El perro con campanilla Había un perro que acostumbraba a morder sin razón. Le puso su amo una campanilla para advertirle a la gente de su presencia cercana, y el can, sonando la campanilla, se fue a la plaza pública a presumir. Mas una sabia perra, ya avanzada de años, le dijo ¿De qué presumes tanto, amigo? Sé que no llevas esa campanilla por tus grandes virtudes Sino para anunciar tu maldad oculta Los halagos que se hacen a sí mismo, los fanfarrones Sólo delatan sus mayores defectos Fin de la fábula Esta grabación es del dominio público Gracias por ver el video.',\n",
              " 'audio27': ' Las fábulas de Esopo Grabado para LibriVox.org por Elo Chito Fábula número 87 El perro que perseguía al león Un perro de caza se encontró con un león y partió en su persecución. Pero el león se volvió rugiendo, y el perro, todo atemorizado, retrocedió rápidamente por el mismo camino. Le vio una zorra y le dijo, ¡Perro infeliz! Primero perseguías al león y ya ni siquiera soportas sus surgidos. Cuando entres a una empresa, mantente siempre listo a afrontar imprevistos que no te imaginabas. Fin de la fábula. Esta grabación es del dominio público. Gracias.'}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fabulas_raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM0D83j8EWiN"
      },
      "source": [
        "# **Ejercicio 2b:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiFG5q88EYHU"
      },
      "source": [
        "* #### **Eliminar el inicio y final comunes de los textos extraídos de cada fábula.**\n",
        "\n",
        "* #### **Sugerencia:** Pueden guardar esta información en un archivo tipo JSON, para que al estar probando diferentes opciones en los ejercicios siguientes, puedan recuperar rápidamente la información de cada video/fábula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkbeTmeon_RP"
      },
      "outputs": [],
      "source": [
        "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
        "\n",
        "\n",
        "patron_inicio = re.compile(\n",
        "    r'^\\s*(?:las\\s+f[áa]bulas\\s+de\\s+(?:esopo|sopo)[\\s.,-]*)?'\n",
        "    r'(?:grabado\\s+para\\s+(?:librivox|librevox)\\.org\\s*)'\n",
        "    r'(?:\\s*por\\s+[^.]+\\s*\\.?\\s*)?'\n",
        "    r'(?:www\\.[^\\s]+\\s*)?'\n",
        "    r'f[áa]bula\\s+n[úu]mero\\s*\\d+[\\s.,-]*',\n",
        "    re.IGNORECASE\n",
        ")\n",
        "\n",
        "patron_final = re.compile(\n",
        "    r'\\s*fin\\s+(?:de\\s+(?:la\\s+)?)?f[áa]bula\\b.*$',\n",
        "    re.IGNORECASE\n",
        ")\n",
        "\n",
        "# Procesar cada fábula\n",
        "fabulas_limpias = {}\n",
        "for key, texto in fabulas_raw.items():\n",
        "    # Eliminar patrón inicial\n",
        "    texto_limpio = patron_inicio.sub('', texto, count=1)\n",
        "\n",
        "    # Eliminar patrón final\n",
        "    texto_limpio = patron_final.sub('', texto_limpio)\n",
        "\n",
        "    # Guardar resultado\n",
        "    fabulas_limpias[key] = texto_limpio.strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rareRWfERTZt",
        "outputId": "1b13be61-5ac8-4273-87fb-240d1f489f69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'audio01': 'El lobo y el cordero en el templo. Dándose cuenta de que era perseguido por un lobo, un pequeño corderito decidió refugiarse en un templo cercano. Lo llamó lobo y le dijo que si el sacrificador lo encontraba allí adentro, lo inmolaría a su dios. Mejor así, replicó el cordero, prefiero ser víctima para un dios a tener que perecer en tus colmillos. Si sin remedio vamos a ser sacrificados, más nos vale que sea con el mayor honor.',\n",
              " 'audio04': 'El lobo y la grulla A un lobo que comía un hueso, se le atragantó el hueso en la garganta y corría por todas partes en busca de auxilio. Encontró en su correa una grulla y le pidió que le salvara de aquella situación, y que enseguida le pagaría por ello. Aceptó la grulla e introdujo su cabeza en la boca del lobo, sacando de la garganta el hueso atravesado Pidió entonces la cancelación de la paga convenida Oye Anida, dijo el lobo, ¿no crees que es suficiente paga con haber sacado tu cabeza sana y salva de mi boca? Nunca hagas favores a malvados, traficantes o corruptos, pues mucha paga tendrías si te dejan sano y salvo',\n",
              " 'audio05': 'El lobo y el caballo. Pasaba un lobo por un sembrado de cebada, pero como no era comida de su gusto, la dejó y siguió su camino. Encontró al rato a un caballo, y le llevó al campo comentándole la gran cantidad de cebada que había hallado, pero que en vez de comérsela a él mejor se la había dejado porque le agradaba más oír el ruido de sus dientes al masticarla pero el caballo le repuso amigo si los lobos comieran cebada no hubieras preferido complacer a tus oídos sino a tu estómago a todo malvado aunque parezca actuar como bueno no debe de creérsele',\n",
              " 'audio06': 'El lobo y el asno. Un lobo fue elegido rey entre sus congéneres y decretó una ley ordenando que lo que cada uno capturase en la casa, lo pusiera en común y lo repartiese por partes iguales entre todos. de esta manera ya no tendrían los lobos que devorarse unos a otros en épocas de hambre pero en eso le escuchó un asno que estaba por ahí cerca y moviendo sus orejas le dijo magnífica idea ha brotado de tu corazón pero ¿por qué has escondido todo tu botín en tu cueva? llévalo a la comunidad y repártelo también como lo has decretado el lobo descubierto y confundido derogó su ley Si alguna vez llegas a tener poder de legislar, sé el primero en cumplir tus propias leyes',\n",
              " 'audio14': 'El lobo y el cabrito encerrado Protegido por la seguridad del corral de una casa, un cabrito vio pasar a un lobo y comenzó a insultarle burlándose ampliamente de él. El lobo serenamente le replicó Infeliz, sé que no eres tú quien me está insultando sino el sitio en que te encuentras Muy a menudo no es el valor sino la ocasión y el lugar quienes proveen el enfrentamiento arrogante ante los poderosos',\n",
              " 'audio22': 'El perro y la almeja Un perro de esos, acostumbrados a comer huevos, al ver una almeja, no lo pensó dos veces, y creyendo que se trataba de un huevo, se la tragó inmediatamente. Desgarradas luego sus entrañas, se sintió muy mal, y se dijo, bien merecido lo tengo por creer que todo lo que veo redondo son huevos nunca tomes un asunto sin antes reflexionar para no entrar luego en extrañas dificultades',\n",
              " 'audio24': 'El perro y el reflejo en el río. Badeaba un perro un río, llevando en su hocico un sabroso pedazo de carne. Vio su propio reflejo en el agua del río, y creyó que aquel reflejo era en realidad otro perro que llevaba un trozo de carne mayor que el suyo. Y deseando adueñarse del pedazo ajeno, soltó el suyo para arrebatar el trozo a su supuesto compadre, pero el resultado fue que se quedó sin el propio y sin el ajeno, este porque no existía, sólo era un reflejo, y el otro, el verdadero, porque se lo llevó a la corriente. Nunca codices el bien ajeno, pues puedes perder lo que ya has adquirido con tu esfuerzo.',\n",
              " 'audio25': 'El perro y el carnicero Penetró un perro en una carnicería y notando que el carnicero estaba muy ocupado con sus clientes, cogió un trozo de carne y salió corriendo. Se volvió el carnicero y viéndole huir y sin poder hacer nada exclamó. Oye amigo, allí donde te encuentre no dejaré de mirarte. No esperes a que suceda un accidente para pensar en cómo evitarlo.',\n",
              " 'audio26': 'El perro con campanilla Había un perro que acostumbraba a morder sin razón. Le puso su amo una campanilla para advertirle a la gente de su presencia cercana, y el can, sonando la campanilla, se fue a la plaza pública a presumir. Mas una sabia perra, ya avanzada de años, le dijo ¿De qué presumes tanto, amigo? Sé que no llevas esa campanilla por tus grandes virtudes Sino para anunciar tu maldad oculta Los halagos que se hacen a sí mismo, los fanfarrones Sólo delatan sus mayores defectos',\n",
              " 'audio27': 'El perro que perseguía al león Un perro de caza se encontró con un león y partió en su persecución. Pero el león se volvió rugiendo, y el perro, todo atemorizado, retrocedió rápidamente por el mismo camino. Le vio una zorra y le dijo, ¡Perro infeliz! Primero perseguías al león y ya ni siquiera soportas sus surgidos. Cuando entres a una empresa, mantente siempre listo a afrontar imprevistos que no te imaginabas.'}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fabulas_limpias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PKaB_Ge0Shc"
      },
      "source": [
        "# **Ejercicio 3:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNrqcQFe0VWR"
      },
      "source": [
        "* #### **Apliquen el proceso de limpieza que consideren adecuado.**\n",
        "\n",
        "* #### **Justifiquen los pasos de limpieza utilizados. Tomen en cuenta que el texto extraído de cada fábula es relativamente pequeño.**\n",
        "\n",
        "* #### **En caso de que decidan no aplicar esta etapa de limpieza, deberán justificarlo.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqwiCCdpq8D_",
        "outputId": "285ec916-d4b2-43e8-d269-24cc134e4d6d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords_es = set(stopwords.words('spanish'))\n",
        "\n",
        "stopwords_extra = {\n",
        "    \"si\", \"allí\", \"así\", \"ello\", \"oye\", \"pues\",\n",
        "    \"sino\", \"sé\",\n",
        "}\n",
        "\n",
        "stopwords_es = stopwords_es.union(stopwords_extra)\n",
        "\n",
        "\n",
        "def limpiar_fabula(texto):\n",
        "    # Eliminamos todo lo que no sean letras\n",
        "    texto = re.sub(r'[^a-zA-ZáéíóúÁÉÍÓÚñÑüÜ]',r' ' , texto).strip().lower()\n",
        "\n",
        "    # Normalización de espacios\n",
        "    texto = re.sub(r'\\s+', ' ', texto)\n",
        "\n",
        "    texto = [tex for tex in texto.split() if tex not in stopwords_es]\n",
        "    return  ' '.join(texto)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7V2kCRJYnBG"
      },
      "outputs": [],
      "source": [
        "fabulas_limpias = {k: limpiar_fabula(v) for k, v in fabulas_limpias.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21igu-BeYoZ_",
        "outputId": "9aaaa5bb-b0a5-47df-cecc-75f5cdaea748"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'audio01': 'lobo cordero templo dándose cuenta perseguido lobo pequeño corderito decidió refugiarse templo cercano llamó lobo dijo sacrificador encontraba adentro inmolaría dios mejor replicó cordero prefiero ser víctima dios tener perecer colmillos remedio vamos ser sacrificados vale mayor honor',\n",
              " 'audio04': 'lobo grulla lobo comía hueso atragantó hueso garganta corría todas partes busca auxilio encontró correa grulla pidió salvara aquella situación enseguida pagaría aceptó grulla introdujo cabeza boca lobo sacando garganta hueso atravesado pidió entonces cancelación paga convenida anida dijo lobo crees suficiente paga haber sacado cabeza sana salva boca nunca hagas favores malvados traficantes corruptos mucha paga dejan sano salvo',\n",
              " 'audio05': 'lobo caballo pasaba lobo sembrado cebada comida gusto dejó siguió camino encontró rato caballo llevó campo comentándole gran cantidad cebada hallado vez comérsela mejor dejado agradaba oír ruido dientes masticarla caballo repuso amigo lobos comieran cebada preferido complacer oídos estómago malvado aunque parezca actuar bueno debe creérsele',\n",
              " 'audio06': 'lobo asno lobo elegido rey congéneres decretó ley ordenando cada capturase casa pusiera común repartiese partes iguales manera lobos devorarse épocas hambre escuchó asno ahí cerca moviendo orejas dijo magnífica idea brotado corazón escondido botín cueva llévalo comunidad repártelo decretado lobo descubierto confundido derogó ley alguna vez llegas tener poder legislar primero cumplir propias leyes',\n",
              " 'audio14': 'lobo cabrito encerrado protegido seguridad corral casa cabrito vio pasar lobo comenzó insultarle burlándose ampliamente lobo serenamente replicó infeliz insultando sitio encuentras menudo valor ocasión lugar proveen enfrentamiento arrogante poderosos',\n",
              " 'audio22': 'perro almeja perro acostumbrados comer huevos ver almeja pensó dos veces creyendo trataba huevo tragó inmediatamente desgarradas luego entrañas sintió mal dijo bien merecido creer veo redondo huevos nunca tomes asunto reflexionar entrar luego extrañas dificultades',\n",
              " 'audio24': 'perro reflejo río badeaba perro río llevando hocico sabroso pedazo carne vio propio reflejo agua río creyó aquel reflejo realidad perro llevaba trozo carne mayor deseando adueñarse pedazo ajeno soltó arrebatar trozo supuesto compadre resultado quedó propio ajeno existía sólo reflejo verdadero llevó corriente nunca codices bien ajeno puedes perder adquirido esfuerzo',\n",
              " 'audio25': 'perro carnicero penetró perro carnicería notando carnicero ocupado clientes cogió trozo carne salió corriendo volvió carnicero viéndole huir poder hacer exclamó amigo encuentre dejaré mirarte esperes suceda accidente pensar cómo evitarlo',\n",
              " 'audio26': 'perro campanilla perro acostumbraba morder razón puso amo campanilla advertirle gente presencia cercana can sonando campanilla plaza pública presumir mas sabia perra avanzada años dijo presumes amigo llevas campanilla grandes virtudes anunciar maldad oculta halagos hacen mismo fanfarrones sólo delatan mayores defectos',\n",
              " 'audio27': 'perro perseguía león perro caza encontró león partió persecución león volvió rugiendo perro atemorizado retrocedió rápidamente mismo camino vio zorra dijo perro infeliz primero perseguías león siquiera soportas surgidos entres empresa mantente siempre listo afrontar imprevistos imaginabas'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fabulas_limpias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2ywrmsMP_EF"
      },
      "source": [
        "# **Ejercicio 4:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xFpnt0A0Ub7"
      },
      "outputs": [],
      "source": [
        "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
        "\n",
        "\n",
        "docs = []\n",
        "for key, text in fabulas_limpias.items():\n",
        "    words = text.split()\n",
        "    docs.append(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XD-fRI8ZcbgV"
      },
      "outputs": [],
      "source": [
        "# Crear el diccionario y el corpus (índice, frecuencia)\n",
        "id2word = corpora.Dictionary(docs)\n",
        "corpus = [id2word.doc2bow(doc) for doc in docs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e2Pn_YLcdHU",
        "outputId": "395bad85-de7f-421b-ff54-ba55a1edd966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fábula 1:\n",
            "Palabras clave: ['perro', 'huevos', 'luego', 'almeja', 'bien', 'nunca', 'dijo', 'reflexionar', 'sintió', 'tomes', 'tragó', 'trataba', 'ver', 'veo', 'dos', 'creer', 'pensó', 'redondo', 'veces', 'entrañas']\n",
            "\n",
            "Fábula 2:\n",
            "Palabras clave: ['hueso', 'grulla', 'paga', 'lobo', 'boca', 'pidió', 'cabeza', 'garganta', 'encontró', 'aceptó', 'malvados', 'entonces', 'mucha', 'favores', 'correa', 'dijo', 'sano', 'atragantó', 'haber', 'corría']\n",
            "\n",
            "Fábula 3:\n",
            "Palabras clave: ['campanilla', 'perro', 'dijo', 'carnicero', 'sólo', 'presencia', 'halagos', 'mayores', 'maldad', 'plaza', 'fanfarrones', 'presumes', 'pública', 'puso', 'llevas', 'razón', 'sabia', 'sonando', 'gente', 'perra']\n",
            "\n",
            "Fábula 4:\n",
            "Palabras clave: ['perro', 'león', 'reflejo', 'campanilla', 'ajeno', 'río', 'trozo', 'carne', 'carnicero', 'pedazo', 'propio', 'volvió', 'mismo', 'sólo', 'amigo', 'vio', 'dijo', 'soportas', 'afrontar', 'siempre']\n",
            "\n",
            "Fábula 5:\n",
            "Palabras clave: ['cebada', 'caballo', 'lobo', 'encontró', 'siguió', 'amigo', 'llevó', 'camino', 'oídos', 'campo', 'sembrado', 'malvado', 'dejado', 'ruido', 'aunque', 'estómago', 'actuar', 'hallado', 'complacer', 'creérsele']\n",
            "\n",
            "Fábula 6:\n",
            "Palabras clave: ['poder', 'carnicero', 'perro', 'lobo', 'ley', 'asno', 'dijo', 'encuentre', 'suceda', 'dejaré', 'cómo', 'corriendo', 'penetró', 'clientes', 'carnicería', 'hacer', 'accidente', 'esperes', 'cogió', 'huir']\n",
            "\n",
            "Fábula 7:\n",
            "Palabras clave: ['lobo', 'paga', 'grulla', 'hueso', 'dijo', 'cabrito', 'replicó', 'dios', 'cordero', 'templo', 'ser', 'garganta', 'cabeza', 'pidió', 'boca', 'infeliz', 'encontró', 'vio', 'partes', 'nunca']\n",
            "\n",
            "Fábula 8:\n",
            "Palabras clave: ['lobo', 'cebada', 'caballo', 'lobos', 'vez', 'asno', 'ley', 'encontró', 'camino', 'poder', 'llevó', 'mejor', 'amigo', 'masticarla', 'agradaba', 'gran', 'preferido', 'ruido', 'complacer', 'comentándole']\n",
            "\n",
            "Fábula 9:\n",
            "Palabras clave: ['ser', 'templo', 'cordero', 'lobo', 'víctima', 'cuenta', 'mayor', 'dijo', 'pequeño', 'cercano', 'inmolaría', 'decidió', 'sacrificados', 'tener', 'dándose', 'dios', 'honor', 'adentro', 'mejor', 'perseguido']\n",
            "\n",
            "Fábula 10:\n",
            "Palabras clave: ['amigo', 'camino', 'perro', 'caballo', 'cebada', 'llevó', 'carnicero', 'encontró', 'lobo', 'león', 'creérsele', 'oír', 'cantidad', 'estómago', 'malvado', 'volvió', 'campo', 'gusto', 'siguió', 'hallado']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Entrenar el modelo LDA\n",
        "lda_model = gensim.models.ldamodel.LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=id2word,\n",
        "    num_topics=10,\n",
        "    chunksize=5,\n",
        "    passes=10,\n",
        "    alpha=0.2,\n",
        "    eta=0.2,\n",
        "    random_state = 17\n",
        ")\n",
        "\n",
        "topicos = {}\n",
        "for idx, topic in lda_model.show_topics(num_topics=10, num_words=20, formatted=False):\n",
        "    palabras = [palabra for palabra, _ in topic]\n",
        "    topicos[f\"fabula_{idx+1}\"] = palabras\n",
        "    print(f\"Fábula {idx+1}:\")\n",
        "    print(\"Palabras clave:\", palabras)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blrrs1sWwkSx"
      },
      "source": [
        "# **Ejercicio 5a y 5b:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWvzQ-aNwsVk"
      },
      "source": [
        "* #### **5a: Mediante el LLM que hayan seleccionado, generar un único enunciado que describa o resuma cada fábula.**\n",
        "\n",
        "* #### **5b: Mediante el LLM que hayan seleccionado, generar tres posibles enunciados diferentes relacionados con la historia de la fábula.**\n",
        "\n",
        "* #### **Sugerencia:** En realidad los dos incisos a y b se pueden obtener con un solo prompt que solicite la información y el formato correspondiente para cada una de estas partes. Por ejemplo, para cada fábula la salida puede ser un primer enunciado genérico que resume o describe dicha temática; seguido de tres enunciados, cada uno hablando sobre una situación o parte diferente de la fábula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418,
          "referenced_widgets": [
            "1e07d222ee4f423787cb321e96a8cb69",
            "5199596e036145ddb62d8f331cd07955",
            "8a97c89a3e274c87a14649faae374009",
            "11b3ffa7abe34cdd94fc804ea435633c",
            "561edfeef24f400b9ccf29e0b7735659",
            "feb35826cef04adf93cb0118f0646554",
            "6beeeb5cc5ff4ac992a516d98061854f",
            "cb3dea8fab9a4b6bb02a71e5497c55d1",
            "725b5212926e4737a360d84ef1fa0167",
            "724d7f2c146f46ffbaf30ba057c8ffc8",
            "746b22ce090642ac95052b1a9f1e45d5",
            "03142408627e4e1485ff3526e69942ef",
            "f8bddd6f06d54ae3b572918580631927",
            "c7413d8be3f14575b9122be722b269d3",
            "6792c02744e04889a798a4de629413c3",
            "5cc36fc95b1144ee958ae46599f1f311",
            "06013bcd8ae84db3866aaa7817dedf0e",
            "64587be72a794c2aa36e490fd01cd6f0",
            "f01ff9d4627d4437b7eb06c3a343eed5",
            "954e2e75bd8540aaa7f7b6312caa85e7",
            "5e0a817f0b9940c8b100b0fb4b030843",
            "0cd8ea11a83b4cceac04d82b7073aae9",
            "be19b4cca66742beb7ae96270a7960f6",
            "ebb3e60ef2bc4c94a417d6a38a2452ca",
            "93904371613a4b61b7e162c5c36872a2",
            "2cf70fca18504304862af1c3ed05b705",
            "720d5df23ef5422db03e013082b1d492",
            "d469205fa10045a1940175105e8c46a7",
            "96793eb3afe54c5d8d8777a58f207e26",
            "0cdc4f077a7643ff9b3d066e2c33584b",
            "10833824cc96466abdeeb51b23ff64b4",
            "6606690af26b48e280caa71700c889b5",
            "c5b8811aab0d43e6a0ac2a6a0a8cf213",
            "9db5b191305645c68716210556432ff9",
            "405bf7e6034842ca94429512e9a60499",
            "10041faca2fe41fb82224156f1aedf44",
            "f62e32189bed42699ff9d89ebbc2d05d",
            "d9dcb6fc44f747c280d11339fdfa0f64",
            "99ed5ad0e5f14090a4e3a37212e77233",
            "87781a4ec6ef42c2b3498a82f05ae85e",
            "61dfb8b2d61149d2b394e6cddab21429",
            "7701bb58b8f4408b9363a84045d4ecfc",
            "8e5d2f238b664719b81507688428a6ac",
            "0a141ec95fed4d8982581324fb182090",
            "d82fa3b713d34810a4e830d333981d02",
            "c3225464e8b547d0bd3e9599446d1142",
            "6060c8370b694957880a43a5a840e685",
            "c6be3e5796f74d86ab25ee5a019a4baf",
            "0e2a9eb31cb84f69a1b07365bc8a19a0",
            "35f1810c99b44a65bfc43241c9d808ad",
            "0eae1a5b83994ab6b4c6117ba7febdfd",
            "044879bf26b547c0b497bf1302b55c23",
            "b05776f440a24d29901c56c6401b6002",
            "2fa41249a74649bbb6ad2ddc1c2bda19",
            "6d690df07d2847f094aa8c4082166946",
            "91f41359786e493988c2bd1c9246c886",
            "06ee36b945f44d5aac4a89dae2d258ea",
            "6b3612677a4e44cbbc2c760eb74e0f66",
            "5709ad7a567a455c89311e606fe2e89d",
            "4bc5c75d750b47968f918ff85d899c5d",
            "3f28c22a3c2b4f0ba27462e3a046112c",
            "e713bd65afb145538eda01dbc0da32e2",
            "733fbaf908ef4f0a887dd576ad7c993b",
            "3ef24c3e05c04dea92fb8e18c178cf8a",
            "453cd483a24249e6a58afb0cf2efd5ac",
            "a0252201cb0949f09ff3bca497470e83",
            "d9fe43e0cf11465e8d83f08ce83965a1",
            "66d63a08a92843cdb2390b890aa95457",
            "9489efab803f42819fff0bf08e4107b6",
            "a56555ec063143909dc7ca1eaa651d47",
            "7de0c29125744f77bb420e94bf1716f8",
            "15442a8009144cfe873e1ed7a34fca0b",
            "bfea2a37b3dd4272b76ec9a720d7389a",
            "1d70f27021684b588fca520063734ff3",
            "60806e10998e4cadbfa50cd5c8c8c597",
            "019daebc6e4a4005989b34ae178f4edb",
            "eaa4922af28e4916809e318ce99847f4",
            "1d01953e310444eaa46a3f27a3a1808d",
            "bc0f5632beed4449a6459ccfa0178e3c",
            "80f8f5e8adad448a87e4c97459145142",
            "12bc206a26f3490991b826897bb396af",
            "57674aec13a84a0a861a74e3ee3dc2a2",
            "36c7ec7b37044175a4ca3a04c1302cdf",
            "732f5527269c4d31b51bc8ee146a3e99",
            "fa1b44564fec4ba982cfba6360a6822d",
            "4d72ec92a0624ea8bb5bc00027a47722",
            "b4861153f7384008bfd74d9657861c7d",
            "17189dce226c495f9ab60608d829c9f8",
            "527772b5d0aa4d4581e2af0f5a7b8e08",
            "f39c002eeaa34f73b0c40b0e0ec672e3",
            "99015ab7331a425bab9d545ddd644ec4",
            "548bc3a4751c4259ae0b449e61aed973",
            "0cfd33ccf099495dbc944437f2054547",
            "84b9c21b06fb4a30923c42dd82c7aa7f",
            "a6992b622c3d471289d630a3cd36abac",
            "333cf2056d94403b9f0afda02aa10f6f",
            "d809b60ddce94e8584c4e5afe89f4ede",
            "83439e3f1d104ac4a4b374a1a7a5af5b",
            "781cc7f5fdea49fc80ee64aec84fc885",
            "22c6af73564b4a028c025b1251063365",
            "47fd83d03e674ae9977d4aba83fc7118",
            "9bcfcf52054b40f580fac04f6015a26c",
            "cb2c76c081974c7f8ba149bd418ff85f",
            "f949d705140d4e6b87143611dca26ff4",
            "56564df329d64e2ea91e6c4d8c75a76f",
            "0d5bf8ce55294185a389ec0100a38a3f",
            "7c14aa338b634114b18157e75607925b",
            "e414d8f9134e4bc29470bab1e072e3c7",
            "6ab886ecd99f4d1b8d27ec495865e3ca",
            "cf6a3be71d6c45bc99808057b31a25b8",
            "02caa69a32a841a39acffbe5ca42fadc",
            "e3422df6956e498a9b2a8c0d85817729",
            "aa7ac16c6fc347e7b9a99af686087526",
            "111961ff230c4704864c6af33c71d0c9",
            "69f41506df5e49a2b577e53fa95ddb42",
            "98b2376e9c344717982781f974d9378a",
            "97e435ec739e446ca0f4aab476e5abbd",
            "cecfcafcbaa94a43a5db3f4e4815df62",
            "8fdd7b94bfa84a2eb844eeba57cfbd32",
            "2032c40eab434c118d32f20fa095b8d7",
            "c0b49866f0e2486fbd2d84cf9dc224f0",
            "304eb187865e404481f6b0c1c39eda4b",
            "4570ff36525d4a3caa0157994ad335d1",
            "f53ce717c91d4754add6dcc1cf3033ca",
            "f02c011ebf1144ea92a9ae8db0ad7705",
            "32bfe3dad82f41d59bf6d80b9999b119",
            "9e15210092cc4e8c9d6916a3b95cc4bc",
            "a12806ad36d9498b9246a0af8129cd17",
            "64ed4dabab514340b9f2a774556edc46",
            "8c1274abe39347dbb2a95ca0f301bae0",
            "03215edea78e485c89d252c0dac47950",
            "07155fa66637470d803745bb42765b57"
          ]
        },
        "id": "Q9UkVPxM0Xii",
        "outputId": "5187e865-8eac-425c-d852-219c9fedd9ad"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e07d222ee4f423787cb321e96a8cb69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03142408627e4e1485ff3526e69942ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be19b4cca66742beb7ae96270a7960f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9db5b191305645c68716210556432ff9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d82fa3b713d34810a4e830d333981d02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91f41359786e493988c2bd1c9246c886",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9fe43e0cf11465e8d83f08ce83965a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d01953e310444eaa46a3f27a3a1808d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "527772b5d0aa4d4581e2af0f5a7b8e08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22c6af73564b4a028c025b1251063365",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02caa69a32a841a39acffbe5ca42fadc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "304eb187865e404481f6b0c1c39eda4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
        "\n",
        "modelo_llm_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelo_llm_id)\n",
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "\n",
        "modelo_llm = AutoModelForCausalLM.from_pretrained(\n",
        "    modelo_llm_id,\n",
        "    quantization_config=quant_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "text_generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=modelo_llm,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GtRnWg31O1n",
        "outputId": "8ac8d534-5d1d-459c-9e34-baa5f4adb2e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "resultados_fabulas = {}\n",
        "\n",
        "for clave, palabras in topicos.items():\n",
        "    palabras_str = ', '.join(palabras[:20])\n",
        "\n",
        "    prompt = (\n",
        "    f\"Palabras clave: {palabras_str}.\\n\\n\"\n",
        "    \"Con base en estas palabras clave, describe en español la fábula de Esopo a la que pertenece. \"\n",
        "    \"Primero incluye un resumen en un solo enunciado. Después, escribe tres subtemas como enseñanzas o moralejas, numeradas del 1 al 3.\"\n",
        ")\n",
        "\n",
        "    resultado = text_generator(\n",
        "        prompt,\n",
        "        max_new_tokens=500,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9\n",
        "    )[0][\"generated_text\"]\n",
        "\n",
        "    resultado = resultado.replace(prompt, '').strip()\n",
        "\n",
        "    resultados_fabulas[clave] = resultado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF0gSJCq1QWP",
        "outputId": "9c66dbee-9a98-4541-97c2-8e9883f1dd59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "FÁBULA: fabula_1\n",
            "--------------------------------------------------\n",
            "Resumen: La historia de Esopo cuenta la de un perro que guardaba huevos de una almeja y, cada vez que se alejaba, decía: \"Luego, almeja, bien, nunca, dijo, reflexionaré, sintió, tomaré, tragó, traté, veré, veo, dos, creeré, pensé, redondo, veces, entrañas.\" Sin embargo, cuando el perro se distrajo y se fue por dos días, la almeja entró y tragó todos los huevos.\n",
            "\n",
            "Subtema 1: La importancia de la vigilancia y la constancia en el logro de un objetivo.\n",
            "La historia de Esopo ilustra la importancia de mantener la atención y la constancia en el logro de un objetivo, ya que el perro se distrajo solo por dos días y perdió todos sus huevos.\n",
            "\n",
            "Subtema 2: La consecuencia de la inacción y el retraso.\n",
            "La historia también enseña que la inacción y el retraso pueden tener consecuencias negativas, como en el caso del perro que no actuó inmediatamente cuando se dio cuenta de que la almeja estaba entrando en su nido.\n",
            "\n",
            "Subtema 3: La importancia de la reflexión y la planificación.\n",
            "Finalmente, la historia de Esopo también resalta la importancia de la reflexión y la planificación en el logro de un objetivo. El perro se distrajo porque se distrajo demasiado con sus pensamientos y no planeó su acción adecuadamente.\n",
            "\n",
            "==================================================\n",
            "\n",
            "FÁBULA: fabula_2\n",
            "--------------------------------------------------\n",
            "Summary: The wolf, tricked by the Crane, pays the price when he swallows the Crane whole.\n",
            "\n",
            "1. Deceit and Consequences: The story of \"The Crane and the Wolf\" teaches the importance of being truthful and the consequences of deceit. In this tale, the Crane tricks the Wolf into believing that the Crane's head is that of the Lamb. The Wolf, unable to resist the tempting offer, swallows the Crane whole, only to regret his decision when he realizes his mistake.\n",
            "\n",
            "2. Appearance vs. Reality: The story also highlights the idea that appearance can be deceiving, as the Crane, despite its small size and seemingly harmless appearance, was able to outsmart the Wolf. This moral can be applied to various aspects of life, reminding us to not judge things or people based on their outward appearance alone.\n",
            "\n",
            "3. Gratitude and Reciprocity: Lastly, the story illustrates the importance of gratitude and reciprocity. The Crane, after being saved by the Farmer, asked for a favor in return. The Wolf, in his turn, was also granted a favor by the Crane, but instead of being grateful, he was consumed by his own greed and deceit. This part of the story shows us the importance of being thankful for the kindness shown to us and paying it forward.\n",
            "\n",
            "==================================================\n",
            "\n",
            "FÁBULA: fabula_3\n",
            "--------------------------------------------------\n",
            "Resumen: La campanilla, una perra, dijo a un carnicero que solo su presencia halagaba a los mayores fanfarrones, maldadosa perra que presumía ser pública y ponía las razones a sus amigos, pero cuando el carnicero la llevó a la plaza para ser pública, la gente se rio y llamó a la perra \"perra\" en vez de \"campanilla\".\n",
            "\n",
            "Subtema 1: La presunción sin fundamento puede conducir a la vergüenza. La perra presumía ser más que lo que realmente era, y cuando fue desmaskada, su vergüenza fue grande.\n",
            "\n",
            "Subtema 2: La verdad siempre sale a la luz. La gente sabía que la perra era una perra y no una campanilla, y no importaba lo que ella dijo, la verdad era que era una perra.\n",
            "\n",
            "Subtema 3: La apariencia engaña a los que no saben lo que realmente es. La gente se engañó con la apariencia de la perra y creyeron que era una campanilla, pero al final, la verdad era que era una perra.\n",
            "\n",
            "==================================================\n",
            "\n",
            "FÁBULA: fabula_4\n",
            "--------------------------------------------------\n",
            "Resumen: La historia de Esopo \"El perro y el león\" trata sobre un perro que, al ver a un león herido en el río y a punto de morir, se acerca a él y le ofrece ayuda. El león, sorprendido, le pregunta cómo es que un perro, su enemigo natural, puede mostrarle tanta compasión. El perro le responde que, al verlo en su miseria, no veía a un león, sino a un animal herido, y que, además, le gustaría que, algún día, si él fuera el herido, el león lo tratara de la misma manera. El león se toma con el perro, prometiendo que si alguna vez necesitaba ayuda, el perro podría confiar en él.\n",
            "\n",
            "Subtema 1: La amistad puede surgir en los lugares más inesperados. En esta historia, un perro y un león se convierten en amigos, demostrando que la compasión y el desinteresado apoyo son valores que pueden unir a cualquiera, incluso a aquellos que normalmente son considerados enemigos.\n",
            "\n",
            "Subtema 2: La apariencia puede engañar. El león, herido y vulnerable, descubre que el perro, su enemigo natural, es capaz de mostrarle compasión y simpatía. Esto ilustra cómo las apariencias pueden engañarnos y que debemos mirar más allá de lo obvio para entender la verdadera naturaleza de las cosas y de las personas.\n",
            "\n",
            "Subtema 3: La bondad debe ser repartida sin esperar nada a cambio. El perro ofrece ayuda al león sin esperar nada a cambio, solo por el bien de alguien más. Esto enseña que la bondad y la compasión deben ser regalos que se dan sin esperar nada a cambio, ya que pueden llenar nuestras vidas y las de otros con felicidad y\n",
            "\n",
            "==================================================\n",
            "\n",
            "FÁBULA: fabula_5\n",
            "--------------------------------------------------\n",
            "Resumen: Una vez había una oveja que encontró un camino lleno de grano de trigo, el camino estaba protegido por un lobo. El caballo que llevaba a la oveja a pastar le dijo que seguía el camino, pero la oveja se temió y se detuvo. El lobo se acercó y le preguntó por qué no seguía el camino. La oveja le dijo que temía a los ruidos del campo y el lobo se reíría y le dijo que el ruido no era de nada y que seguía el camino. La oveja, aún temerosa, no lo hizo y se quedó. Mientras tanto, un amigo de la oveja que llevaba el grano a sembrar pasó por allí y le preguntó por qué la oveja no seguía el camino. La oveja le dijo que temía a los ruidos y el amigo le dijo que el lobo los estaba intentando engañar. La oveja, ahora más confiada, siguió el camino y llegó a un gran campo lleno de hierba, donde se encontró con el amigo que sembraba. El lobo, molesto por que la oveja no cayera en su trampa, se fue.\n",
            "\n",
            "1. La miedo a lo desconocido nos puede impedir avanzar en las buenas oportunidades de la vida.\n",
            "2. Los amigos son importantes para guiarnos y darnos consejos cuando estamos inciertos.\n",
            "3. No creer en las mentiras y engaños de los malvados nos permite actuar con sabiduría y seguridad.\n",
            "\n",
            "Resumen: La oveja se detuvo al ver un camino lleno de grano porque estaba asustada de los ruidos del campo. El caballo la animó a seguir el camino, pero ella se rehusó. Un amigo de la oveja que llevaba el grano a sembrar pasó y le dijo que el lobo que protegía el camino la estaba engañando. La\n",
            "\n",
            "==================================================\n",
            "\n",
            "FÁBULA: fabula_6\n",
            "--------------------------------------------------\n",
            "Resumen: La ley dice que el asno es responsable de cualquier daño que cause al entrar en una carnicería. Un día, el asno, que era muy temerario y corrió por el pueblo, entró en una carnicería en llamas sin darse cuenta. Los clientes corrieron a salvar sus negocios y el perro del carnicero, el lobo en disfraz, atacó al asno. El carnicero, que se encontraba allí, dijo que el asno había penetrado a su propia voluntad y causado el incendio. El asno, que no sabía hablar, no pudo defenderse. Los clientes esperaron a que sucediera algo y, cuando el perro atacó, el asno huyó. El carnicero, que no deseaba perder el asno, lo dejó ir.\n",
            "\n",
            "Subtema 1: La inocencia no siempre es visible. La ley puede juzgar equivocadamente, y los falsos acusados pueden ser inocentes.\n",
            "\n",
            "Subtema 2: La falsa acusación puede llevar a daños innecesarios. Los rumores y la falta de comprobación de hechos pueden causar daños a alguien inocente.\n",
            "\n",
            "Subtema 3: La verdad siempre sale a la luz. La verdadera situación se revela a medida que el tiempo pasa y las cosas se desvelan.\n",
            "\n",
            "==================================================\n",
            "\n",
            "FÁBULA: fabula_7\n",
            "--------------------------------------------------\n",
            "Resumen: La grulla, que no podía alcanzar una hoja que estaba en el árbol, pidió ayuda al lobo. El lobo le dijo que debía poner la cabeza en la garganta del cabrito para que le diera su boca para alcanzarla. La grulla, infeliz, se negó. Luego, el lobo pidió ayuda al cordero y le dijo lo mismo. El cordero, temeroso, accedió. El lobo, entonces, tomó la hoja y se fue, dejando a la grulla y al cordero con sus partes intercambiadas.\n",
            "\n",
            "1. La astucia y la maldad de los poderosos: La grulla, que era débil y no podía alcanzar la hoja, buscó ayuda. Ella confiaba en la fuerza del lobo para obtener lo que deseaba. Sin embargo, el lobo no era benevolente y aprovechó la situación para engañar a la grulla y al cordero, dejándolos con sus partes intercambiadas.\n",
            "\n",
            "2. La cobardía y la prudencia: El cordero, temeroso de la fuerza del lobo, accedió a intercambiar sus partes con la grulla. Aunque esto le causó sufrimiento inmediato, salvó su vida al no quererse meter en una situación peligrosa. La grulla, por otro lado, se negó a hacer lo que le pedía el lobo y su obstinación la llevó a una pérdida.\n",
            "\n",
            "3. La apariencia y la realidad: La grulla pensó que el lobo era fuerte y le podía ayudar a obtener la hoja. Sin embargo, el lobo era maligno y aprovechó la situación para engañarla y al cordero. La apariencia de ser fuerte y poderoso no era lo mismo que serlo en realidad.\n",
            "\n",
            "==================================================\n",
            "\n",
            "FÁBULA: fabula_8\n",
            "--------------------------------------------------\n",
            "Resumen:\n",
            "El lobo, engañado por el asno, le lleva a la cebada, pero al llegar, el asno se queda atado y el lobo queda complacido con la comida, hasta que el dueño de la cebada regresa y el lobo, más fuerte, es el que queda atrapado.\n",
            "\n",
            "Subtema 1:\n",
            "La falsa confianza puede traer peligros. (El asno se confiaba en el lobo y le llevó a la cebada, sin darse cuenta de que era una trampa.)\n",
            "\n",
            "Subtema 2:\n",
            "El que parece amigo puede ser el enemigo. (El lobo engañó al asno y lo hizo atrapar, revelando que no era un amigo sino un enemigo.)\n",
            "\n",
            "Subtema 3:\n",
            "El poder no es absoluto y puede cambiar de manos. (El lobo, al principio, tenía el poder de atrapar al asno, pero al final, el dueño de la cebada lo atrapó.)\n",
            "\n",
            "Fábula de Esopo: \"El Lobo y el Asno\"\n",
            "\n",
            "Resumen:\n",
            "El astuto lobo engaña al tonto asno prometiéndole que le llevaría a comer cebada en el camino, sin embargo, al llegar a la gran cebada, el asno se queda atado y el lobo se queda a gozar de la comida. Sin embargo, su complacencia es corta, ya que el dueño de la cebada regresa y el lobo, que había olvidado que no era solo el dueño de la cebada sino también el dueño del camino, es el que queda atrapado.\n",
            "\n",
            "Subtema 1:\n",
            "La apariencia deben de engañarnos menos que la realidad. (El asno fue engañado por la falsa apariencia de amistad del lobo, lo que lo llevó a quedarse atado.)\n",
            "\n",
            "Subtema 2:\n",
            "El poder debe ser utilizado con precaución. (\n",
            "\n",
            "==================================================\n",
            "\n",
            "FÁBULA: fabula_9\n",
            "--------------------------------------------------\n",
            "1. The shepherd who saved a lamb from a wolf and was later sacrificed by the villagers who were grateful for his protection.\n",
            "\n",
            "Subtemas:\n",
            "\n",
            "1.1. Self-sacrifice for the greater good is a noble act.\n",
            "1.2. The importance of showing gratitude and not taking kindness for granted.\n",
            "1.3. Appearances can be deceiving; the seemingly weak or insignificant can be the most heroic.\n",
            "\n",
            "The shepherd who, putting himself in danger, saved a lamb from a wolf, was later sacrificed by the villagers who, grateful for his protection, offered him as a thank-offering to their god.\n",
            "\n",
            "1.1. (Self-sacrifice for the greater good is a noble act)\n",
            "The shepherd, without expecting anything in return, put his own life at risk to save the lamb. His selfless act not only saved the lamb but also protected the entire flock, demonstrating that putting others before oneself can lead to greater good.\n",
            "\n",
            "1.2. (The importance of showing gratitude and not taking kindness for granted)\n",
            "The villagers, appreciating the shepherd's bravery and selflessness, chose to honor him with a sacrifice. However, they failed to recognize that the shepherd was the very victim they intended to offer to their god. This shows the importance of being grateful for the kindness and acts of generosity that we receive, and not taking them for granted.\n",
            "\n",
            "1.3. (Appearances can be deceiving; the seemingly weak or insignificant can be the most heroic)\n",
            "At first glance, the shepherd appeared to be a small, insignificant figure. However, when faced with danger, he proved to be a brave and selfless hero, risking his own life to save the lamb and ultimately becoming a sacrificial offering. This demonstrates that appearances can be deceiving, and that the seemingly weak or insignificant among us can possess great strength and courage.\n",
            "\n",
            "==================================================\n",
            "\n",
            "FÁBULA: fabula_10\n",
            "--------------------------------------------------\n",
            "1. La fábula de \"El Amigo Lobo\" es sobre un perro que lleva a un caballo a un campo de cebada para beber y se deja engañar por un lobo, que se come al caballo y luego se come al perro cuando llega el carnicero.\n",
            "2. Subtema 1: No confiar demasiado en los aparentes amigos.\n",
            "3. Subtema 2: La cobardía puede costar caro.\n",
            "4. Subtema 3: La buena voluntad no debe ser explotada.\n",
            "\n",
            "La fábula de \"El Amigo Lobo\" es una famosa historia de Esopo en la que un perro lleva a un caballo a un campo de cebada para beber, pero se deja engañar por un lobo disfrazado de amigo. El lobo come al caballo y luego, cuando el carnicero viene, come al perro también.\n",
            "\n",
            "1. Subtema 1: No confiar demasiado en los aparentes amigos (Lazos de amistad y traición)\n",
            "El perro, confiando en el lobo como en un amigo, se deja engañar y termina poniendo en peligro a su compañero, el caballo. Esto sirve como una lección sobre la importancia de ser cautelosos con quienes nosotros confiamos y cómo la traición puede llegar de las más inesperadas fuentes.\n",
            "2. Subtema 2: La cobardía puede costar caro (El riesgo de no actuar)\n",
            "El perro, en lugar de defenderse o alertar al caballo del peligro, se deja engañar y termina perdiendo su propia vida. Esto sirve como una lección sobre el riesgo de la cobardía y cómo puede costarnos más que simplemente dejar que los eventos transcurran sin interferir.\n",
            "3. Subtema 3: La buena voluntad no debe ser explotada (El uso y abuso de la confianza)\n",
            "El lob\n",
            "\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "for clave, texto in resultados_fabulas.items():\n",
        "    print(f\"\\nFÁBULA: {clave}\")\n",
        "    print(\"-\" * 50)\n",
        "    print(texto)\n",
        "    print(\"\\n\" + \"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx-dZSFJz9cK"
      },
      "source": [
        "# **Ejercicio 6:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w3usdaC0BCj"
      },
      "source": [
        "* #### **Incluyan sus conclusiones de la actividad audio-a-texto:**\n",
        "\n",
        "\n",
        "\n",
        "La actividad permitió aplicar un flujo completo de procesamiento de lenguaje natural (NLP). Se inició con la transcripción de archivos de audio de las fábulas de Esopo y finalizó con la generación de resúmenes temáticos. Todo el proceso permitió comprender el potencial de los modelos actuales para el análisis de contenido de audio.\n",
        "\n",
        "Se utilizaron dos enfoques para la conversión de audio a texto: la mayoría de los audios fueron transcritos utilizando la API de Google Speech Recognition, pero debido a que en algunos de los casos se generaban textos incompletos, se trabajó también con el modelo Wav2Vec2 de Facebook (entrenada para el idioma español), el cual resultó ser una alternativa eficaz. Este desafío enfatizó la necesidad de adaptabilidad técnica en proyectos de NLP.\n",
        "\n",
        "Aunque las fábulas eran breves, se aplicaron procesos de limpieza, como la eliminación de stopwords, tildes y signos innecesarios. Este paso aseguró una entrada adecuada para los modelos de tópicos y a los LLM, mejorando así la coherencia y la calidad de los resultados.\n",
        "\n",
        "La aplicación del modelo LDA permitió extraer palabras clave relevantes por cada fábula, y demostró cómo los modelos probabilísticos pueden capturar tópicos dominantes aún en textos pequeños.\n",
        "\n",
        "Se decidió utilizar el modelo GPT-4o-mini, el cual generó descripciones sintéticas y subtemas para cada fábula, poniendo en evidencia la capacidad de los modelos de lenguaje para interpretar contextos y generar contenidos coherentes.\n",
        "\n",
        "Esta actividad no solo permitió aplicar técnicas avanzadas de PLN, sino también nos permitió reflexionar sobre las decisiones críticas del preprocesamiento y selección de modelos. La capacidad de ajustar herramientas según los desafíos de los datos, como por ejemplo, la calidad del audio o la complejidad del lenguaje fue un aprendizaje esencial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtB5Q3m41YQ0"
      },
      "source": [
        "# **Fin de la actividad LDA y LMM: audio-a-texto**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Kx-dZSFJz9cK"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
    
