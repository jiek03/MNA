{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hVND8xY2OKY"
      },
      "source": [
        "# **Procesamiento de Lenguaje Natural**\n",
        "\n",
        "## Maestría en Inteligencia Artificial Aplicada\n",
        "#### Tecnológico de Monterrey\n",
        "#### Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "### **Adtividad en Equipos Semanas 7 y 8 : LDA y LMM audio-a-texto**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aimHVFOv23lm"
      },
      "source": [
        "* **Nombres y matrículas:**\n",
        "\n",
        "  *   Elemento de lista\n",
        "  *   Elemento de lista\n",
        "  *   Elemento de lista\n",
        "\n",
        "* **Número de Equipo:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jimvsiVgjMg"
      },
      "source": [
        "* ##### **En cada ejercicio pueden importar los paquetes o librerías que requieran.**\n",
        "\n",
        "* ##### **En cada ejercicio pueden incluir las celdas y líneas de código que deseen.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BtP-Sk0DT-M"
      },
      "source": [
        "# **Ejercicio 1:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh78pKeMghfe"
      },
      "source": [
        "* #### **Liga de los audios de las fábulas de Esopo:** https://www.gutenberg.org/ebooks/21144\n",
        "\n",
        "* #### **Descargar los 10 archivos de audio solicitados: 1, 4, 5, 6, 14, 22, 24, 25, 26, 27.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jv3ylkd--A2C"
      },
      "outputs": [],
      "source": [
        "#!pip uninstall -y scipy numpy\n",
        "#!pip install numpy==1.25.2\n",
        "#!pip install scipy==1.11.3  # Compatible con numpy>=1.25\n",
        "#!pip install gensim==4.3.2\n",
        "#!pip install bitsandbytes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfs5Zxc9j7Uf",
        "outputId": "45fa1df5-9e7f-43a4-a6c2-58a8bd07cfbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Directorio con los audios\n",
        "DIR = '/content/drive/MyDrive/Colab Notebooks/MNA/TC5043 - Procesamiento de lenguaje natural/Semana 6 y 7'\n",
        "\n",
        "import json\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "from gensim import corpora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUup4C8nHKB5",
        "outputId": "bbc00ce7-2a59-448d-ebfc-31df35aac666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline, AutoProcessor, AutoModelForSpeechSeq2Seq, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import librosa\n",
        "import torch\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "login(userdata.get('miHuggingFace'))\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Usando dispositivo: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uR9ULdUY6nVe"
      },
      "outputs": [],
      "source": [
        "# Audios a trabajar\n",
        "audio_ids = [1, 4, 5, 6, 14, 22, 24, 25, 26, 27]\n",
        "audio_paths = {f'audio{str(i).zfill(2)}': os.path.join(DIR, f'21144-{i}.mp3') for i in audio_ids}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uYgtCvvJSmq"
      },
      "source": [
        "# **Ejercicio 2a:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAQjVP2HkoZY"
      },
      "source": [
        "* #### **Comenten el por qué del modelo seleccionado para extracción del texto de los audios.**\n",
        "\n",
        "* #### **Extraer el contenido de los audios en texto.**\n",
        "\n",
        "* #### **Sugerencia:** pueden extraerlo en un formato de diccionario, clave:valor $→$ {audio01:fabula01, ...}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2XGo3g3H-VO"
      },
      "outputs": [],
      "source": [
        "audios_data = {}\n",
        "for audio_key, audio_path in audio_paths.items():\n",
        "    if os.path.exists(audio_path):\n",
        "        audio, sample_rate = librosa.load(audio_path,\n",
        "                                          sr=16000   # los modelos Wav2Vec2 requieren un muestreo (sample rate) de 16Hz.\n",
        "                                          )\n",
        "        audios_data[audio_key] = (audio, sample_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvVsMsJwKhcy",
        "outputId": "9e775a21-2afb-4e17-f9dd-dcd7105e07c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_id = \"openai/whisper-large-v3\"    # una versión ligera de v3\n",
        "\n",
        "# Cargamos el modelo:\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "modelo = AutoModelForSpeechSeq2Seq.from_pretrained(model_id).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGpR1wB1NbBi",
        "outputId": "6e5f331d-d41c-4688-930b-5aa855ebfbe7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda\n"
          ]
        }
      ],
      "source": [
        "asr_pipeline = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=modelo,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    torch_dtype=torch.float32,\n",
        "    device=device,\n",
        "    return_timestamps=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3k5sLGhnO1d",
        "outputId": "8c268898-32e0-4dbe-9150-406d607bbdca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n",
            "You have passed language=es, but also have set `forced_decoder_ids` to [[1, None], [2, 50360]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of language=es.\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de audios procesados: 10\n"
          ]
        }
      ],
      "source": [
        "# Diccionario para almacenar los textos extraídos\n",
        "fabulas_raw = {}\n",
        "\n",
        "# Extraer texto de cada audio usando el pipeline\n",
        "for audio_key, (audio, sample_rate) in audios_data.items():\n",
        "    # Configurar los parámetros de generación\n",
        "    generate_kwargs = {\"language\": \"es\"}\n",
        "\n",
        "    # Usar el pipeline\n",
        "    result = asr_pipeline(audio, generate_kwargs=generate_kwargs)\n",
        "\n",
        "    # Extraer solo el texto de la transcripción\n",
        "    transcription = result[\"text\"]\n",
        "    fabulas_raw[audio_key] = transcription\n",
        "\n",
        "print(f\"Total de audios procesados: {len([k for k, v in fabulas_raw.items() if v])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K7mALE8Opzf",
        "outputId": "d0af1f44-6b89-4b38-8407-8e8c65c20289"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'audio01': ' Las Fábulas de Esopo. Grabado para LibriVox.org por Paulino. www.paulino.info Fábula número 61. El lobo y el cordero en el templo. Dándose cuenta de que era perseguido por un lobo, un pequeño corderito decidió refugiarse en un templo cercano. Lo llamó lobo y le dijo que si el sacrificador lo encontraba allí adentro, lo inmolaría a su dios. Mejor así, replicó el cordero, prefiero ser víctima para un dios a tener que perecer en tus colmillos. Si sin remedio vamos a ser sacrificados, más nos vale que sea con el mayor honor. Fin de la fábula. Esta es una grabación del dominio público.',\n",
              " 'audio04': ' Las fábulas de Esopo grabado para LibriVox.org por Roberto Antonio Muñoz Fábula número 64 El lobo y la grulla A un lobo que comía un hueso, se le atragantó el hueso en la garganta y corría por todas partes en busca de auxilio. Encontró en su correa una grulla y le pidió que le salvara de aquella situación, y que enseguida le pagaría por ello. Aceptó la grulla e introdujo su cabeza en la boca del lobo, sacando de la garganta el hueso atravesado Pidió entonces la cancelación de la paga convenida Oye Anida, dijo el lobo, ¿no crees que es suficiente paga con haber sacado tu cabeza sana y salva de mi boca? Nunca hagas favores a malvados, traficantes o corruptos, pues mucha paga tendrías si te dejan sano y salvo Fin de fábula Esta grabación es de dominio público',\n",
              " 'audio05': ' Las fábulas de Sopo, grabado para LibriVox.org por Karen Savage. Fábula número 65. El lobo y el caballo. Pasaba un lobo por un sembrado de cebada, pero como no era comida de su gusto, la dejó y siguió su camino. Encontró al rato a un caballo, y le llevó al campo comentándole la gran cantidad de cebada que había hallado, pero que en vez de comérsela a él mejor se la había dejado porque le agradaba más oír el ruido de sus dientes al masticarla pero el caballo le repuso amigo si los lobos comieran cebada no hubieras preferido complacer a tus oídos sino a tu estómago a todo malvado aunque parezca actuar como bueno no debe de creérsele fin de fábula esta grabación es de dominio público Gracias por ver el video.',\n",
              " 'audio06': ' Las fábulas de Esopo, grabado para LibriVox.org por Alejandro González Calderón. Fábula número 66, El lobo y el asno. Un lobo fue elegido rey entre sus congéneres y decretó una ley ordenando que lo que cada uno capturase en la casa, lo pusiera en común y lo repartiese por partes iguales entre todos. de esta manera ya no tendrían los lobos que devorarse unos a otros en épocas de hambre pero en eso le escuchó un asno que estaba por ahí cerca y moviendo sus orejas le dijo magnífica idea ha brotado de tu corazón pero ¿por qué has escondido todo tu botín en tu cueva? llévalo a la comunidad y repártelo también como lo has decretado el lobo descubierto y confundido derogó su ley Si alguna vez llegas a tener poder de legislar, sé el primero en cumplir tus propias leyes Fin de la fábula, esta grabación es de dominio público',\n",
              " 'audio14': ' Las fábulas de Sopo Grabado para LibriVox.org por Elochito Fábula número 74 El lobo y el cabrito encerrado Protegido por la seguridad del corral de una casa, un cabrito vio pasar a un lobo y comenzó a insultarle burlándose ampliamente de él. El lobo serenamente le replicó Infeliz, sé que no eres tú quien me está insultando sino el sitio en que te encuentras Muy a menudo no es el valor sino la ocasión y el lugar quienes proveen el enfrentamiento arrogante ante los poderosos Fin de la fábula Esta grabación es del dominio público Gracias.',\n",
              " 'audio22': ' Las fábulas de Esopo Grabado para LibriVox.org por Elochito Fábula número 82 El perro y la almeja Un perro de esos, acostumbrados a comer huevos, al ver una almeja, no lo pensó dos veces, y creyendo que se trataba de un huevo, se la tragó inmediatamente. Desgarradas luego sus entrañas, se sintió muy mal, y se dijo, bien merecido lo tengo por creer que todo lo que veo redondo son huevos nunca tomes un asunto sin antes reflexionar para no entrar luego en extrañas dificultades Fin de la fábula. Esta grabación es del dominio público.',\n",
              " 'audio24': ' Las fábulas de Sopo. Grabado para LibriVox.org por Karen Savage. Fábula número 84. El perro y el reflejo en el río. Badeaba un perro un río, llevando en su hocico un sabroso pedazo de carne. Vio su propio reflejo en el agua del río, y creyó que aquel reflejo era en realidad otro perro que llevaba un trozo de carne mayor que el suyo. Y deseando adueñarse del pedazo ajeno, soltó el suyo para arrebatar el trozo a su supuesto compadre, pero el resultado fue que se quedó sin el propio y sin el ajeno, este porque no existía, sólo era un reflejo, y el otro, el verdadero, porque se lo llevó a la corriente. Nunca codices el bien ajeno, pues puedes perder lo que ya has adquirido con tu esfuerzo. Fin de fábula Esta grabación es de dominio público',\n",
              " 'audio25': ' Las Fábulas de Esopo Grabado para LibreVox.org Fábula número 85 El perro y el carnicero Penetró un perro en una carnicería y notando que el carnicero estaba muy ocupado con sus clientes, cogió un trozo de carne y salió corriendo. Se volvió el carnicero y viéndole huir y sin poder hacer nada exclamó. Oye amigo, allí donde te encuentre no dejaré de mirarte. No esperes a que suceda un accidente para pensar en cómo evitarlo. Fin de fábula. Esta grabación es de dominio público. Gracias por ver el video.',\n",
              " 'audio26': ' Las fábulas de Esopo Grabado para LibriVox.org por Elochito Fábula número 86 El perro con campanilla Había un perro que acostumbraba a morder sin razón. Le puso su amo una campanilla para advertirle a la gente de su presencia cercana, y el can, sonando la campanilla, se fue a la plaza pública a presumir. Mas una sabia perra, ya avanzada de años, le dijo ¿De qué presumes tanto, amigo? Sé que no llevas esa campanilla por tus grandes virtudes Sino para anunciar tu maldad oculta Los halagos que se hacen a sí mismo, los fanfarrones Sólo delatan sus mayores defectos Fin de la fábula Esta grabación es del dominio público Gracias por ver el video.',\n",
              " 'audio27': ' Las fábulas de Esopo Grabado para LibriVox.org por Elo Chito Fábula número 87 El perro que perseguía al león Un perro de caza se encontró con un león y partió en su persecución. Pero el león se volvió rugiendo, y el perro, todo atemorizado, retrocedió rápidamente por el mismo camino. Le vio una zorra y le dijo, ¡Perro infeliz! Primero perseguías al león y ya ni siquiera soportas sus surgidos. Cuando entres a una empresa, mantente siempre listo a afrontar imprevistos que no te imaginabas. Fin de la fábula. Esta grabación es del dominio público. Gracias.'}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fabulas_raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM0D83j8EWiN"
      },
      "source": [
        "# **Ejercicio 2b:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiFG5q88EYHU"
      },
      "source": [
        "* #### **Eliminar el inicio y final comunes de los textos extraídos de cada fábula.**\n",
        "\n",
        "* #### **Sugerencia:** Pueden guardar esta información en un archivo tipo JSON, para que al estar probando diferentes opciones en los ejercicios siguientes, puedan recuperar rápidamente la información de cada video/fábula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkbeTmeon_RP"
      },
      "outputs": [],
      "source": [
        "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
        "\n",
        "\n",
        "patron_inicio = re.compile(\n",
        "    r'^\\s*(?:las\\s+f[áa]bulas\\s+de\\s+(?:esopo|sopo)[\\s.,-]*)?'\n",
        "    r'(?:grabado\\s+para\\s+(?:librivox|librevox)\\.org\\s*)'\n",
        "    r'(?:\\s*por\\s+[^.]+\\s*\\.?\\s*)?'\n",
        "    r'(?:www\\.[^\\s]+\\s*)?'\n",
        "    r'f[áa]bula\\s+n[úu]mero\\s*\\d+[\\s.,-]*',\n",
        "    re.IGNORECASE\n",
        ")\n",
        "\n",
        "patron_final = re.compile(\n",
        "    r'\\s*fin\\s+(?:de\\s+(?:la\\s+)?)?f[áa]bula\\b.*$',\n",
        "    re.IGNORECASE\n",
        ")\n",
        "\n",
        "# Procesar cada fábula\n",
        "fabulas_limpias = {}\n",
        "for key, texto in fabulas_raw.items():\n",
        "    # Eliminar patrón inicial\n",
        "    texto_limpio = patron_inicio.sub('', texto, count=1)\n",
        "\n",
        "    # Eliminar patrón final\n",
        "    texto_limpio = patron_final.sub('', texto_limpio)\n",
        "\n",
        "    # Guardar resultado\n",
        "    fabulas_limpias[key] = texto_limpio.strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rareRWfERTZt",
        "outputId": "b348279f-0f8e-4cb7-bb7e-1890f9ab19d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'audio01': 'El lobo y el cordero en el templo. Dándose cuenta de que era perseguido por un lobo, un pequeño corderito decidió refugiarse en un templo cercano. Lo llamó lobo y le dijo que si el sacrificador lo encontraba allí adentro, lo inmolaría a su dios. Mejor así, replicó el cordero, prefiero ser víctima para un dios a tener que perecer en tus colmillos. Si sin remedio vamos a ser sacrificados, más nos vale que sea con el mayor honor.',\n",
              " 'audio04': 'El lobo y la grulla A un lobo que comía un hueso, se le atragantó el hueso en la garganta y corría por todas partes en busca de auxilio. Encontró en su correa una grulla y le pidió que le salvara de aquella situación, y que enseguida le pagaría por ello. Aceptó la grulla e introdujo su cabeza en la boca del lobo, sacando de la garganta el hueso atravesado Pidió entonces la cancelación de la paga convenida Oye Anida, dijo el lobo, ¿no crees que es suficiente paga con haber sacado tu cabeza sana y salva de mi boca? Nunca hagas favores a malvados, traficantes o corruptos, pues mucha paga tendrías si te dejan sano y salvo',\n",
              " 'audio05': 'El lobo y el caballo. Pasaba un lobo por un sembrado de cebada, pero como no era comida de su gusto, la dejó y siguió su camino. Encontró al rato a un caballo, y le llevó al campo comentándole la gran cantidad de cebada que había hallado, pero que en vez de comérsela a él mejor se la había dejado porque le agradaba más oír el ruido de sus dientes al masticarla pero el caballo le repuso amigo si los lobos comieran cebada no hubieras preferido complacer a tus oídos sino a tu estómago a todo malvado aunque parezca actuar como bueno no debe de creérsele',\n",
              " 'audio06': 'El lobo y el asno. Un lobo fue elegido rey entre sus congéneres y decretó una ley ordenando que lo que cada uno capturase en la casa, lo pusiera en común y lo repartiese por partes iguales entre todos. de esta manera ya no tendrían los lobos que devorarse unos a otros en épocas de hambre pero en eso le escuchó un asno que estaba por ahí cerca y moviendo sus orejas le dijo magnífica idea ha brotado de tu corazón pero ¿por qué has escondido todo tu botín en tu cueva? llévalo a la comunidad y repártelo también como lo has decretado el lobo descubierto y confundido derogó su ley Si alguna vez llegas a tener poder de legislar, sé el primero en cumplir tus propias leyes',\n",
              " 'audio14': 'El lobo y el cabrito encerrado Protegido por la seguridad del corral de una casa, un cabrito vio pasar a un lobo y comenzó a insultarle burlándose ampliamente de él. El lobo serenamente le replicó Infeliz, sé que no eres tú quien me está insultando sino el sitio en que te encuentras Muy a menudo no es el valor sino la ocasión y el lugar quienes proveen el enfrentamiento arrogante ante los poderosos',\n",
              " 'audio22': 'El perro y la almeja Un perro de esos, acostumbrados a comer huevos, al ver una almeja, no lo pensó dos veces, y creyendo que se trataba de un huevo, se la tragó inmediatamente. Desgarradas luego sus entrañas, se sintió muy mal, y se dijo, bien merecido lo tengo por creer que todo lo que veo redondo son huevos nunca tomes un asunto sin antes reflexionar para no entrar luego en extrañas dificultades',\n",
              " 'audio24': 'El perro y el reflejo en el río. Badeaba un perro un río, llevando en su hocico un sabroso pedazo de carne. Vio su propio reflejo en el agua del río, y creyó que aquel reflejo era en realidad otro perro que llevaba un trozo de carne mayor que el suyo. Y deseando adueñarse del pedazo ajeno, soltó el suyo para arrebatar el trozo a su supuesto compadre, pero el resultado fue que se quedó sin el propio y sin el ajeno, este porque no existía, sólo era un reflejo, y el otro, el verdadero, porque se lo llevó a la corriente. Nunca codices el bien ajeno, pues puedes perder lo que ya has adquirido con tu esfuerzo.',\n",
              " 'audio25': 'El perro y el carnicero Penetró un perro en una carnicería y notando que el carnicero estaba muy ocupado con sus clientes, cogió un trozo de carne y salió corriendo. Se volvió el carnicero y viéndole huir y sin poder hacer nada exclamó. Oye amigo, allí donde te encuentre no dejaré de mirarte. No esperes a que suceda un accidente para pensar en cómo evitarlo.',\n",
              " 'audio26': 'El perro con campanilla Había un perro que acostumbraba a morder sin razón. Le puso su amo una campanilla para advertirle a la gente de su presencia cercana, y el can, sonando la campanilla, se fue a la plaza pública a presumir. Mas una sabia perra, ya avanzada de años, le dijo ¿De qué presumes tanto, amigo? Sé que no llevas esa campanilla por tus grandes virtudes Sino para anunciar tu maldad oculta Los halagos que se hacen a sí mismo, los fanfarrones Sólo delatan sus mayores defectos',\n",
              " 'audio27': 'El perro que perseguía al león Un perro de caza se encontró con un león y partió en su persecución. Pero el león se volvió rugiendo, y el perro, todo atemorizado, retrocedió rápidamente por el mismo camino. Le vio una zorra y le dijo, ¡Perro infeliz! Primero perseguías al león y ya ni siquiera soportas sus surgidos. Cuando entres a una empresa, mantente siempre listo a afrontar imprevistos que no te imaginabas.'}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fabulas_limpias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PKaB_Ge0Shc"
      },
      "source": [
        "# **Ejercicio 3:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNrqcQFe0VWR"
      },
      "source": [
        "* #### **Apliquen el proceso de limpieza que consideren adecuado.**\n",
        "\n",
        "* #### **Justifiquen los pasos de limpieza utilizados. Tomen en cuenta que el texto extraído de cada fábula es relativamente pequeño.**\n",
        "\n",
        "* #### **En caso de que decidan no aplicar esta etapa de limpieza, deberán justificarlo.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqwiCCdpq8D_",
        "outputId": "bac2488a-a41c-47f2-faf9-73ba75bff2a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords_es = set(stopwords.words('spanish'))\n",
        "\n",
        "stopwords_extra = {\n",
        "    \"si\", \"allí\", \"así\", \"ello\", \"oye\", \"pues\",\n",
        "    \"sino\", \"sé\",\n",
        "}\n",
        "\n",
        "stopwords_es = stopwords_es.union(stopwords_extra)\n",
        "\n",
        "\n",
        "def limpiar_fabula(texto):\n",
        "    # Eliminamos todo lo que no sean letras\n",
        "    texto = re.sub(r'[^a-zA-ZáéíóúÁÉÍÓÚñÑüÜ]',r' ' , texto).strip().lower()\n",
        "\n",
        "    # Normalización de espacios\n",
        "    texto = re.sub(r'\\s+', ' ', texto)\n",
        "\n",
        "    texto = [tex for tex in texto.split() if tex not in stopwords_es]\n",
        "    return  ' '.join(texto)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7V2kCRJYnBG"
      },
      "outputs": [],
      "source": [
        "fabulas_limpias = {k: limpiar_fabula(v) for k, v in fabulas_limpias.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21igu-BeYoZ_",
        "outputId": "d495bb90-9867-441b-9f2c-28cc7eab5168"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'audio01': 'lobo cordero templo dándose cuenta perseguido lobo pequeño corderito decidió refugiarse templo cercano llamó lobo dijo sacrificador encontraba adentro inmolaría dios mejor replicó cordero prefiero ser víctima dios tener perecer colmillos remedio vamos ser sacrificados vale mayor honor',\n",
              " 'audio04': 'lobo grulla lobo comía hueso atragantó hueso garganta corría todas partes busca auxilio encontró correa grulla pidió salvara aquella situación enseguida pagaría aceptó grulla introdujo cabeza boca lobo sacando garganta hueso atravesado pidió entonces cancelación paga convenida anida dijo lobo crees suficiente paga haber sacado cabeza sana salva boca nunca hagas favores malvados traficantes corruptos mucha paga dejan sano salvo',\n",
              " 'audio05': 'lobo caballo pasaba lobo sembrado cebada comida gusto dejó siguió camino encontró rato caballo llevó campo comentándole gran cantidad cebada hallado vez comérsela mejor dejado agradaba oír ruido dientes masticarla caballo repuso amigo lobos comieran cebada preferido complacer oídos estómago malvado aunque parezca actuar bueno debe creérsele',\n",
              " 'audio06': 'lobo asno lobo elegido rey congéneres decretó ley ordenando cada capturase casa pusiera común repartiese partes iguales manera lobos devorarse épocas hambre escuchó asno ahí cerca moviendo orejas dijo magnífica idea brotado corazón escondido botín cueva llévalo comunidad repártelo decretado lobo descubierto confundido derogó ley alguna vez llegas tener poder legislar primero cumplir propias leyes',\n",
              " 'audio14': 'lobo cabrito encerrado protegido seguridad corral casa cabrito vio pasar lobo comenzó insultarle burlándose ampliamente lobo serenamente replicó infeliz insultando sitio encuentras menudo valor ocasión lugar proveen enfrentamiento arrogante poderosos',\n",
              " 'audio22': 'perro almeja perro acostumbrados comer huevos ver almeja pensó dos veces creyendo trataba huevo tragó inmediatamente desgarradas luego entrañas sintió mal dijo bien merecido creer veo redondo huevos nunca tomes asunto reflexionar entrar luego extrañas dificultades',\n",
              " 'audio24': 'perro reflejo río badeaba perro río llevando hocico sabroso pedazo carne vio propio reflejo agua río creyó aquel reflejo realidad perro llevaba trozo carne mayor deseando adueñarse pedazo ajeno soltó arrebatar trozo supuesto compadre resultado quedó propio ajeno existía sólo reflejo verdadero llevó corriente nunca codices bien ajeno puedes perder adquirido esfuerzo',\n",
              " 'audio25': 'perro carnicero penetró perro carnicería notando carnicero ocupado clientes cogió trozo carne salió corriendo volvió carnicero viéndole huir poder hacer exclamó amigo encuentre dejaré mirarte esperes suceda accidente pensar cómo evitarlo',\n",
              " 'audio26': 'perro campanilla perro acostumbraba morder razón puso amo campanilla advertirle gente presencia cercana can sonando campanilla plaza pública presumir mas sabia perra avanzada años dijo presumes amigo llevas campanilla grandes virtudes anunciar maldad oculta halagos hacen mismo fanfarrones sólo delatan mayores defectos',\n",
              " 'audio27': 'perro perseguía león perro caza encontró león partió persecución león volvió rugiendo perro atemorizado retrocedió rápidamente mismo camino vio zorra dijo perro infeliz primero perseguías león siquiera soportas surgidos entres empresa mantente siempre listo afrontar imprevistos imaginabas'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fabulas_limpias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2ywrmsMP_EF"
      },
      "source": [
        "# **Ejercicio 4:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xFpnt0A0Ub7"
      },
      "outputs": [],
      "source": [
        "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
        "\n",
        "\n",
        "docs = []\n",
        "for key, text in fabulas_limpias.items():\n",
        "    words = text.split()\n",
        "    docs.append(words)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XD-fRI8ZcbgV"
      },
      "outputs": [],
      "source": [
        "# Crear el diccionario y el corpus (índice, frecuencia)\n",
        "id2word = corpora.Dictionary(docs)\n",
        "corpus = [id2word.doc2bow(doc) for doc in docs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e2Pn_YLcdHU",
        "outputId": "aa73d98f-4082-4dea-cb69-a9f25219a18b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fábula 1:\n",
            "Palabras clave: ['perro', 'huevos', 'luego', 'almeja', 'bien', 'nunca', 'dijo', 'redondo', 'creer', 'ver', 'veo', 'veces', 'trataba', 'tragó', 'tomes', 'pensó', 'sintió', 'reflexionar', 'dos', 'entrañas']\n",
            "\n",
            "Fábula 2:\n",
            "Palabras clave: ['hueso', 'grulla', 'paga', 'lobo', 'boca', 'pidió', 'cabeza', 'garganta', 'encontró', 'aceptó', 'malvados', 'entonces', 'mucha', 'favores', 'correa', 'dijo', 'sano', 'atragantó', 'haber', 'corría']\n",
            "\n",
            "Fábula 3:\n",
            "Palabras clave: ['campanilla', 'perro', 'dijo', 'carnicero', 'sólo', 'sonando', 'razón', 'presencia', 'sabia', 'pública', 'puso', 'gente', 'presumes', 'fanfarrones', 'plaza', 'maldad', 'mayores', 'halagos', 'llevas', 'perra']\n",
            "\n",
            "Fábula 4:\n",
            "Palabras clave: ['perro', 'león', 'reflejo', 'campanilla', 'río', 'ajeno', 'trozo', 'carne', 'carnicero', 'propio', 'pedazo', 'volvió', 'mismo', 'sólo', 'amigo', 'vio', 'dijo', 'soportas', 'afrontar', 'siempre']\n",
            "\n",
            "Fábula 5:\n",
            "Palabras clave: ['cebada', 'caballo', 'lobo', 'encontró', 'siguió', 'amigo', 'llevó', 'camino', 'oídos', 'campo', 'sembrado', 'malvado', 'dejado', 'ruido', 'aunque', 'estómago', 'actuar', 'hallado', 'complacer', 'creérsele']\n",
            "\n",
            "Fábula 6:\n",
            "Palabras clave: ['poder', 'carnicero', 'perro', 'lobo', 'ley', 'asno', 'dijo', 'esperes', 'accidente', 'penetró', 'carnicería', 'clientes', 'cogió', 'corriendo', 'cómo', 'dejaré', 'suceda', 'encuentre', 'hacer', 'huir']\n",
            "\n",
            "Fábula 7:\n",
            "Palabras clave: ['lobo', 'paga', 'grulla', 'hueso', 'dijo', 'cabrito', 'dios', 'replicó', 'cordero', 'templo', 'ser', 'garganta', 'cabeza', 'pidió', 'boca', 'infeliz', 'encontró', 'vio', 'partes', 'nunca']\n",
            "\n",
            "Fábula 8:\n",
            "Palabras clave: ['lobo', 'cebada', 'caballo', 'lobos', 'vez', 'asno', 'ley', 'encontró', 'camino', 'poder', 'llevó', 'mejor', 'amigo', 'masticarla', 'agradaba', 'gran', 'preferido', 'ruido', 'complacer', 'comentándole']\n",
            "\n",
            "Fábula 9:\n",
            "Palabras clave: ['ser', 'templo', 'cordero', 'lobo', 'víctima', 'cuenta', 'mayor', 'dijo', 'pequeño', 'cercano', 'inmolaría', 'decidió', 'sacrificados', 'tener', 'dándose', 'dios', 'honor', 'adentro', 'mejor', 'perseguido']\n",
            "\n",
            "Fábula 10:\n",
            "Palabras clave: ['amigo', 'camino', 'perro', 'caballo', 'cebada', 'llevó', 'carnicero', 'encontró', 'lobo', 'león', 'creérsele', 'oír', 'cantidad', 'estómago', 'malvado', 'volvió', 'campo', 'gusto', 'siguió', 'hallado']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Entrenar el modelo LDA\n",
        "lda_model = gensim.models.ldamodel.LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=id2word,\n",
        "    num_topics=10,\n",
        "    chunksize=5,\n",
        "    passes=10,\n",
        "    alpha=0.2,\n",
        "    eta=0.2,\n",
        "    random_state=17\n",
        ")\n",
        "\n",
        "topicos = {}\n",
        "for idx, topic in lda_model.show_topics(num_topics=10, num_words=20, formatted=False):\n",
        "    palabras = [palabra for palabra, _ in topic]\n",
        "    topicos[f\"fabula_{idx+1}\"] = palabras\n",
        "    print(f\"Fábula {idx+1}:\")\n",
        "    print(\"Palabras clave:\", palabras)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blrrs1sWwkSx"
      },
      "source": [
        "# **Ejercicio 5a y 5b:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWvzQ-aNwsVk"
      },
      "source": [
        "* #### **5a: Mediante el LLM que hayan seleccionado, generar un único enunciado que describa o resuma cada fábula.**\n",
        "\n",
        "* #### **5b: Mediante el LLM que hayan seleccionado, generar tres posibles enunciados diferentes relacionados con la historia de la fábula.**\n",
        "\n",
        "* #### **Sugerencia:** En realidad los dos incisos a y b se pueden obtener con un solo prompt que solicite la información y el formato correspondiente para cada una de estas partes. Por ejemplo, para cada fábula la salida puede ser un primer enunciado genérico que resume o describe dicha temática; seguido de tres enunciados, cada uno hablando sobre una situación o parte diferente de la fábula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "2d095ec3f8b24a0aa980a75deeabb15d",
            "d2cc8dee28d242b0bf0878e59909b6c9",
            "f6b3b7e53ec8471cb4af0d60014b8763",
            "45ca6de2efea485fb6577fa5dd592aef",
            "6b86ab7ae6ba4b25bc3dab6a66e4f0cb",
            "e0cbdc2fc3dd46c78d0cbce9e931abe0",
            "c0e7708718fe48b59bbf165b439d7f7c",
            "956eeefb27294c2e89788bcbe9f405dd",
            "7245740525354430a473b5c306e67fa7",
            "44f6c6cb80604c55adc8f3b01395b9be",
            "dda765dd41da43fdbed5022e3e742700"
          ]
        },
        "id": "Q9UkVPxM0Xii",
        "outputId": "cd8257ec-4ad9-4fdb-a98b-8bdb57738442"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d095ec3f8b24a0aa980a75deeabb15d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
        "\n",
        "modelo_llm_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelo_llm_id)\n",
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "\n",
        "modelo_llm = AutoModelForCausalLM.from_pretrained(\n",
        "    modelo_llm_id,\n",
        "    quantization_config=quant_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "text_generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=modelo_llm,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzgtasBd874Y"
      },
      "outputs": [],
      "source": [
        "resultados_fabulas = {}\n",
        "\n",
        "for clave, palabras in topicos.items():\n",
        "    palabras_str = ', '.join(palabras[:20])\n",
        "\n",
        "    prompt = (\n",
        "    f\"Palabras clave: {palabras_str}.\\n\\n\"\n",
        "    \"Con base en estas palabras clave, describe en español la fábula de Esopo a la que pertenece. \"\n",
        "    \"Primero incluye un resumen en un solo enunciado. Después, escribe tres subtemas como enseñanzas o moralejas, numeradas del 1 al 3.\"\n",
        ")\n",
        "\n",
        "    resultado = text_generator(\n",
        "        prompt,\n",
        "        max_new_tokens=500,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9\n",
        "    )[0][\"generated_text\"]\n",
        "\n",
        "    resultado = resultado.replace(prompt, '').strip()\n",
        "\n",
        "    resultados_fabulas[clave] = resultado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y22bix09Vhxc"
      },
      "outputs": [],
      "source": [
        "for clave, texto in resultados_fabulas.items():\n",
        "    print(f\"\\nFÁBULA: {clave}\")\n",
        "    print(\"-\" * 50)\n",
        "    print(texto)\n",
        "    print(\"\\n\" + \"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx-dZSFJz9cK"
      },
      "source": [
        "# **Ejercicio 6:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w3usdaC0BCj"
      },
      "source": [
        "* #### **Incluyan sus conclusiones de la actividad audio-a-texto:**\n",
        "\n",
        "La actividad permitió aplicar un flujo completo de procesamiento de lenguaje natural (NLP). Se inició con la transcripción de archivos de audio de las fábulas de Esopo y finalizó con la generación de resúmenes temáticos. Todo el proceso permitió comprender el potencial de los modelos actuales para el análisis de contenido de audio.\n",
        "\n",
        "Se utilizaron dos enfoques para la conversión de audio a texto: la mayoría de los audios fueron transcritos utilizando la API de Google Speech Recognition, pero debido a que en algunos de los casos se generaban textos incompletos, se trabajó también con el modelo Wav2Vec2 de Facebook (entrenada para el idioma español), el cual resultó ser una alternativa eficaz. Este desafío enfatizó la necesidad de adaptabilidad técnica en proyectos de NLP.\n",
        "\n",
        "Aunque las fábulas eran breves, se aplicaron procesos de limpieza, como la eliminación de stopwords, tildes y signos innecesarios. Este paso aseguró una entrada adecuada para los modelos de tópicos y a los LLM, mejorando así la coherencia y la calidad de los resultados.\n",
        "\n",
        "La aplicación del modelo LDA permitió extraer palabras clave relevantes por cada fábula, y demostró cómo los modelos probabilísticos pueden capturar tópicos dominantes aún en textos pequeños.\n",
        "\n",
        "Se decidió utilizar el modelo GPT-4o-mini, el cual generó descripciones sintéticas y subtemas para cada fábula, poniendo en evidencia la capacidad de los modelos de lenguaje para interpretar contextos y generar contenidos coherentes.\n",
        "\n",
        "Esta actividad no solo permitió aplicar técnicas avanzadas de PLN, sino también nos permitió reflexionar sobre las decisiones críticas del preprocesamiento y selección de modelos. La capacidad de ajustar herramientas según los desafíos de los datos, como por ejemplo, la calidad del audio o la complejidad del lenguaje fue un aprendizaje esencial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtB5Q3m41YQ0"
      },
      "source": [
        "# **Fin de la actividad LDA y LMM: audio-a-texto**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Kx-dZSFJz9cK"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2d095ec3f8b24a0aa980a75deeabb15d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2cc8dee28d242b0bf0878e59909b6c9",
              "IPY_MODEL_f6b3b7e53ec8471cb4af0d60014b8763",
              "IPY_MODEL_45ca6de2efea485fb6577fa5dd592aef"
            ],
            "layout": "IPY_MODEL_6b86ab7ae6ba4b25bc3dab6a66e4f0cb"
          }
        },
        "44f6c6cb80604c55adc8f3b01395b9be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45ca6de2efea485fb6577fa5dd592aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44f6c6cb80604c55adc8f3b01395b9be",
            "placeholder": "​",
            "style": "IPY_MODEL_dda765dd41da43fdbed5022e3e742700",
            "value": " 0/3 [00:00&lt;?, ?it/s]"
          }
        },
        "6b86ab7ae6ba4b25bc3dab6a66e4f0cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7245740525354430a473b5c306e67fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "956eeefb27294c2e89788bcbe9f405dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0e7708718fe48b59bbf165b439d7f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2cc8dee28d242b0bf0878e59909b6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0cbdc2fc3dd46c78d0cbce9e931abe0",
            "placeholder": "​",
            "style": "IPY_MODEL_c0e7708718fe48b59bbf165b439d7f7c",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "dda765dd41da43fdbed5022e3e742700": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0cbdc2fc3dd46c78d0cbce9e931abe0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6b3b7e53ec8471cb4af0d60014b8763": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_956eeefb27294c2e89788bcbe9f405dd",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7245740525354430a473b5c306e67fa7",
            "value": 0
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
